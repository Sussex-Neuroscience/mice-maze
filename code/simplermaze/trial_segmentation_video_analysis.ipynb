{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76170361",
   "metadata": {},
   "source": [
    "# Trial segmentation script\n",
    "\n",
    "This notebook is intended for the breakdown, classification and analysis of the behavioural states shown in the video, starting from a trial segmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe2464a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment and run if there are issues with the version of the dependencies\n",
    "#  %pip uninstall -y pandas numpy\n",
    "# %pip install --upgrade --force-reinstall \"numpy<2\"\n",
    "# %pip install --upgrade --force-reinstall opencv-python\n",
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce349f8",
   "metadata": {},
   "source": [
    "- `trial segmentation` takes the output of simplerCode.py (video + .csv), and segments the video based on mouse entry and exit times in the video rather than the .csv\n",
    "- we then will manually sort the trials into `exploitative`, `explorative` and `nest`\n",
    "- extract speed and trajectories per trial\n",
    "- identify behavioural syllables with keypoint moseq 2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f877740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q numpy pandas opencv-python\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a803352",
   "metadata": {},
   "source": [
    "create a csv to video dictionary with the mice and trials we are interested in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e8e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/\"\n",
    "\n",
    "#this is where the csv files of interest are stored\n",
    "csvs = []\n",
    "\n",
    "#this is where we store the videos\n",
    "videos = []\n",
    "\n",
    "\n",
    "for i in os.listdir(main_dir):\n",
    "    if \"6357\" in i or \"6359\" in i:\n",
    "        mouse_dir = os.path.join(main_dir, i)\n",
    "        # print(mouse_dir[-10:])\n",
    "        for session in os.listdir(mouse_dir):\n",
    "            if 'habituation' in session or '1.1' in session or \"3.5\" in session or \"3.6\" in session or \"3.7\" in session or \"3.8\" in session:\n",
    "                session_dir = os.path.join(mouse_dir, session)\n",
    "                # print(f\"    -{session_dir[-10:]}\")\n",
    "\n",
    "                for file in os.listdir(session_dir):\n",
    "\n",
    "                    full_path_file = os.path.join(session_dir, file)\n",
    "\n",
    "                    if \"trial_info.csv\" in file and \"clean\" not in file:\n",
    "                        csvs.append(full_path_file)\n",
    "                        # print(f\"        -{file}\")\n",
    "                    elif \"mp4\" in file:\n",
    "                        videos.append(full_path_file)\n",
    "\n",
    "csv_video = dict(zip(csvs, videos))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c145ad",
   "metadata": {},
   "source": [
    "in this notebook we will select the rois in the first frame of the first video, and they will become the reference rois. We then use homography to adapt the rois to the other videos, and have the option of accepting/redrawing/skipping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa46c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS to where you want the reference ROI CSV saved ===\n",
    "REF_ROIS_CSV = main_dir + \"rois_reference.csv\" # <- put your desired path here\n",
    "\n",
    "# the ordered ROI names you’ll draw on the first (reference) video\n",
    "ROI_NAMES = [\"entrance1\", \"entrance2\"]\n",
    "\n",
    "# homography scale for feature matching (smaller = faster; 0.5–0.8 is a good range)\n",
    "PYR_SCALE = 0.75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aad0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_video_any(path: str):\n",
    "    for backend in (cv.CAP_MSMF, cv.CAP_FFMPEG, cv.CAP_DSHOW, cv.CAP_ANY):\n",
    "        cap = cv.VideoCapture(path, backend)\n",
    "        ok, frame = cap.read()\n",
    "        if ok and frame is not None:\n",
    "            cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "            return cap\n",
    "        try: cap.release()\n",
    "        except Exception: pass\n",
    "    return None\n",
    "\n",
    "def grab_first_frame(video_path: str) -> Optional[np.ndarray]:\n",
    "    cap = open_video_any(video_path)\n",
    "    if cap is None:\n",
    "        return None\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    return frame if ok else None\n",
    "\n",
    "def save_rois_csv(dest_csv: Path, rows: List[Tuple[str,int,int,int,int]]) -> None:\n",
    "    df = pd.DataFrame(rows, columns=[\"name\",\"x\",\"y\",\"w\",\"h\"])\n",
    "    dest_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(dest_csv, index=False)\n",
    "\n",
    "def load_rois_long(csv_path: str) -> List[Tuple[str,int,int,int,int]]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    need = {\"name\",\"x\",\"y\",\"w\",\"h\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        raise ValueError(f\"ROI CSV must have columns {need}; got {set(df.columns)}\")\n",
    "    out = []\n",
    "    for name, x, y, w, h in df[[\"name\",\"x\",\"y\",\"w\",\"h\"]].itertuples(index=False, name=None):\n",
    "        out.append((str(name).lower(), int(x), int(y), int(w), int(h)))\n",
    "    return out\n",
    "\n",
    "def overlay_rois(image: np.ndarray, rows: List[Tuple[str,int,int,int,int]], color=(0,255,0)) -> np.ndarray:\n",
    "    out = image.copy()\n",
    "    for name, x, y, w, h in rows:\n",
    "        cv.rectangle(out, (x, y), (x+w, y+h), color, 2)\n",
    "        cv.putText(out, name, (x, max(20, y-10)), cv.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv.LINE_AA)\n",
    "    return out\n",
    "\n",
    "def draw_rois_on_first_frame(video_path: str, roi_names=ROI_NAMES, scale: float = 2.0\n",
    "                             ) -> List[Tuple[str,int,int,int,int]]:\n",
    "    \"\"\"\n",
    "    Interactively draw the ROIs in the order given by roi_names.\n",
    "    Returns [(name,x,y,w,h)] in original-resolution coordinates.\n",
    "    \"\"\"\n",
    "    frame = grab_first_frame(video_path)\n",
    "    if frame is None:\n",
    "        raise RuntimeError(f\"Could not open/read: {video_path}\")\n",
    "\n",
    "    disp = cv.resize(frame, None, fx=scale, fy=scale, interpolation=cv.INTER_LINEAR)\n",
    "    win = \"Draw ROIs - ENTER to confirm, ESC to skip\"\n",
    "    cv.namedWindow(win, cv.WINDOW_NORMAL)\n",
    "    cv.resizeWindow(win, disp.shape[1], disp.shape[0])\n",
    "    try:\n",
    "        cv.setWindowProperty(win, cv.WND_PROP_TOPMOST, 1)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    selections: List[Tuple[str,int,int,int,int]] = []\n",
    "    overlays: List[Tuple[str,int,int,int,int]] = []\n",
    "\n",
    "    for name in roi_names:\n",
    "        frame_show = disp.copy()\n",
    "        for nm, sx, sy, sw, sh in overlays:\n",
    "            cv.rectangle(frame_show, (sx, sy), (sx+sw, sy+sh), (255,0,0), 2)\n",
    "            cv.putText(frame_show, nm, (sx, max(20, sy-10)), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,0), 2, cv.LINE_AA)\n",
    "        cv.putText(frame_show, f\"Draw {name} then ENTER (ESC to skip)\", (20, 40),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3, cv.LINE_AA)\n",
    "\n",
    "        r = cv.selectROI(win, frame_show, fromCenter=False, showCrosshair=True)\n",
    "        if r == (0,0,0,0):\n",
    "            print(f\"[WARN] Skipped ROI: {name}\")\n",
    "            continue\n",
    "        x = int(r[0] / scale); y = int(r[1] / scale)\n",
    "        w = int(r[2] / scale); h = int(r[3] / scale)\n",
    "        selections.append((name.lower(), x, y, w, h))\n",
    "        overlays.append((name, r[0], r[1], r[2], r[3]))\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    if not selections:\n",
    "        raise RuntimeError(\"No ROIs were drawn.\")\n",
    "    return selections\n",
    "\n",
    "# --- homography (ORB + BFMatcher + RANSAC) ---\n",
    "def detect_homography(ref_img: np.ndarray, cur_img: np.ndarray) -> Optional[np.ndarray]:\n",
    "    g1 = cv.cvtColor(ref_img, cv.COLOR_BGR2GRAY) if ref_img.ndim == 3 else ref_img\n",
    "    g2 = cv.cvtColor(cur_img, cv.COLOR_BGR2GRAY) if cur_img.ndim == 3 else cur_img\n",
    "    orb = cv.ORB_create(nfeatures=5000, scaleFactor=1.2, edgeThreshold=15, patchSize=31)\n",
    "    k1, d1 = orb.detectAndCompute(g1, None)\n",
    "    k2, d2 = orb.detectAndCompute(g2, None)\n",
    "    if d1 is None or d2 is None or len(k1) < 20 or len(k2) < 20:\n",
    "        return None\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(d1, d2)\n",
    "    if len(matches) < 20:\n",
    "        return None\n",
    "    matches = sorted(matches, key=lambda m: m.distance)[:500]\n",
    "    src = np.float32([k1[m.queryIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "    dst = np.float32([k2[m.trainIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "    H, mask = cv.findHomography(src, dst, cv.RANSAC, 3.0)\n",
    "    if H is None: return None\n",
    "    if mask is not None and int(mask.sum()) < 20:\n",
    "        return None\n",
    "    return H\n",
    "\n",
    "def project_rect(x: int, y: int, w: int, h: int, H: np.ndarray) -> Tuple[int,int,int,int]:\n",
    "    pts = np.array([[x,y], [x+w,y], [x+w,y+h], [x,y+h]], dtype=np.float32).reshape(-1,1,2)\n",
    "    proj = cv.perspectiveTransform(pts, H).reshape(-1,2)\n",
    "    xs, ys = proj[:,0], proj[:,1]\n",
    "    x0 = max(0, int(np.floor(xs.min()))); y0 = max(0, int(np.floor(ys.min())))\n",
    "    x1 = int(np.ceil(xs.max())); y1 = int(np.ceil(ys.max()))\n",
    "    return x0, y0, max(1, x1-x0), max(1, y1-y0)\n",
    "\n",
    "def auto_rois_from_reference(cur_img: np.ndarray,\n",
    "                             ref_img: np.ndarray,\n",
    "                             ref_rows: List[Tuple[str,int,int,int,int]],\n",
    "                             pyr_scale: float = 0.75) -> Optional[List[Tuple[str,int,int,int,int]]]:\n",
    "    \"\"\"\n",
    "    Estimate homography (optionally on downscaled images) and map ref ROIs -> current frame.\n",
    "    \"\"\"\n",
    "    if pyr_scale != 1.0:\n",
    "        def S(a): return np.array([[a,0,0],[0,a,0],[0,0,1]], dtype=np.float32)\n",
    "        ref_s = cv.resize(ref_img, None, fx=pyr_scale, fy=pyr_scale)\n",
    "        cur_s = cv.resize(cur_img, None, fx=pyr_scale, fy=pyr_scale)\n",
    "        Hs = detect_homography(ref_s, cur_s)\n",
    "        if Hs is None: return None\n",
    "        H = np.linalg.inv(S(pyr_scale)) @ Hs @ S(pyr_scale)\n",
    "    else:\n",
    "        H = detect_homography(ref_img, cur_img)\n",
    "        if H is None: return None\n",
    "\n",
    "    out = []\n",
    "    for name, x, y, w, h in ref_rows:\n",
    "        x2, y2, w2, h2 = project_rect(x, y, w, h, H)\n",
    "        out.append((name, x2, y2, w2, h2))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb4ee029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pairs: 10\n"
     ]
    }
   ],
   "source": [
    "# Your code that builds csv_video should already have run.\n",
    "# csv_video maps: trial_csv_path -> video_path\n",
    "assert isinstance(csv_video, dict) and len(csv_video) > 0, \"csv_video is empty\"\n",
    "print(\"Found pairs:\", len(csv_video))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7703f468",
   "metadata": {},
   "source": [
    "commenting roi selection for reference video out so that we don't reprocess stuff for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference video: C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6357\\2024-08-27_13_05_196357session3.5\\6357_2024-08-27_13_05_19s3.5.mp4\n",
      "Saved reference ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/rois_reference.csv\n"
     ]
    }
   ],
   "source": [
    "# # pick the first (CSV -> VIDEO) pair from your dict\n",
    "# first_csv, first_video = next(iter(csv_video.items()))\n",
    "# print(\"Reference video:\", first_video)\n",
    "\n",
    "# # draw interactively on the first video\n",
    "# ref_rows = draw_rois_on_first_frame(first_video, roi_names=ROI_NAMES, scale=2.0)\n",
    "# save_rois_csv(Path(REF_ROIS_CSV), ref_rows)\n",
    "# print(\"Saved reference ROIs ->\", REF_ROIS_CSV)\n",
    "# #\n",
    "# # (optional) quick visual check\n",
    "# frame0 = grab_first_frame(first_video)\n",
    "# vis0 = overlay_rois(frame0, ref_rows)\n",
    "# cv.imshow(\"Reference ROIs (press any key to close)\", vis0); cv.waitKey(0); cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f76366",
   "metadata": {},
   "source": [
    "This iterates over all the other videos in csv_video, adapts the ROIs via homography, shows you a quick preview `(Y=accept, R=redraw, Q=skip)`, and saves a per-video ROI file named \"<video_stem>_rois.csv\" next to each video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5bbc6",
   "metadata": {},
   "source": [
    "also commenting this out for now so that we don't redraw the rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13ac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual redraw...\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6357/2024-08-28_11_58_146357session3.6/6357_2024-08-28_11_58_14s3.6_rois.csv  (redrawn_manual)\n",
      "Manual redraw...\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6357/2024-08-29_10_23_026357session3.7/6357_2024-08-29_10_23_02s3.7_rois.csv  (redrawn_manual)\n",
      "Manual redraw...\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6357/2024-08-30_10_07_556357session3.8/6357_2024-08-30_10_07_55s3.8_rois.csv  (redrawn_manual)\n",
      "Manual redraw...\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6357/habituation/6357_2024-08-15_11_23_10_rois.csv  (redrawn_manual)\n",
      "Manual redraw...\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6359/2024-08-27_14_08_356359session3.5/6359_2024-08-27_14_08_35s3.5_rois.csv  (redrawn_manual)\n",
      "Manual redraw...\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6359/2024-08-28_13_28_276359session3.6/6359_2024-08-28_13_28_27s3.6_rois.csv  (redrawn_manual)\n",
      "Manual redraw...\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6359/2024-08-29_11_39_286359session3.7/6359_2024-08-29_11_39_28s3.7_rois.csv  (redrawn_manual)\n",
      "Manual redraw...\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6359/2024-08-30_11_28_106359session3.8/6359_2024-08-30_11_28_10s3.8_rois.csv  (redrawn_manual)\n",
      "Manual redraw...\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6359/habituation/6359_2024-08-15_14_05_08_rois.csv  (redrawn_manual)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>roi_csv</th>\n",
       "      <th>how</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>redrawn_manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>redrawn_manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>redrawn_manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>redrawn_manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>redrawn_manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>redrawn_manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>redrawn_manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>redrawn_manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>redrawn_manual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               video  \\\n",
       "0  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "1  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "2  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "3  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "4  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "5  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "6  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "7  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "8  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "\n",
       "                                             roi_csv             how  \n",
       "0  C:/Users/shahd/Box/Awake Project/Maze data/sim...  redrawn_manual  \n",
       "1  C:/Users/shahd/Box/Awake Project/Maze data/sim...  redrawn_manual  \n",
       "2  C:/Users/shahd/Box/Awake Project/Maze data/sim...  redrawn_manual  \n",
       "3  C:/Users/shahd/Box/Awake Project/Maze data/sim...  redrawn_manual  \n",
       "4  C:/Users/shahd/Box/Awake Project/Maze data/sim...  redrawn_manual  \n",
       "5  C:/Users/shahd/Box/Awake Project/Maze data/sim...  redrawn_manual  \n",
       "6  C:/Users/shahd/Box/Awake Project/Maze data/sim...  redrawn_manual  \n",
       "7  C:/Users/shahd/Box/Awake Project/Maze data/sim...  redrawn_manual  \n",
       "8  C:/Users/shahd/Box/Awake Project/Maze data/sim...  redrawn_manual  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ref_frame = grab_first_frame(first_video)\n",
    "# ref_rows  = load_rois_long(REF_ROIS_CSV)\n",
    "\n",
    "# adapted_summary = []\n",
    "\n",
    "# for trials_csv, video in csv_video.items():\n",
    "#     if video == first_video:\n",
    "#         # skip the reference; it's already drawn and saved\n",
    "#         continue\n",
    "\n",
    "#     vp = Path(video).resolve()\n",
    "#     out_csv = vp.with_suffix(\"\").as_posix() + \"_rois.csv\"\n",
    "\n",
    "#     cur_frame = grab_first_frame(str(vp))\n",
    "#     if cur_frame is None:\n",
    "#         print(f\"[SKIP] Cannot open video: {vp}\")\n",
    "#         continue\n",
    "\n",
    "#     # try homography-based transfer\n",
    "#     adapted = auto_rois_from_reference(cur_frame, ref_frame, ref_rows, pyr_scale=PYR_SCALE)\n",
    "\n",
    "#     # preview: Y=accept, R=manual redraw, Q=skip\n",
    "#     if adapted is not None:\n",
    "#         preview = overlay_rois(cur_frame, adapted, color=(0,255,0))\n",
    "#     else:\n",
    "#         preview = overlay_rois(cur_frame, ref_rows, color=(0,255,255))  # fallback preview\n",
    "\n",
    "#     win = f\"Adapted ROIs: {vp.name}  [Y=accept | R=redraw | Q=skip]\"\n",
    "#     cv.namedWindow(win, cv.WINDOW_NORMAL)\n",
    "#     cv.imshow(win, preview)\n",
    "#     key = cv.waitKey(0) & 0xFF\n",
    "#     cv.destroyAllWindows()\n",
    "\n",
    "#     if key in (ord('y'), ord('Y')) and adapted is not None:\n",
    "#         rows = adapted\n",
    "#         reason = \"accepted_adapted\"\n",
    "#     elif key in (ord('r'), ord('R')):\n",
    "#         print(\"Manual redraw...\")\n",
    "#         rows = draw_rois_on_first_frame(str(vp), roi_names=[n for n, *_ in ref_rows], scale=2.0)\n",
    "#         reason = \"redrawn_manual\"\n",
    "#     elif key in (ord('q'), ord('Q')):\n",
    "#         print(f\"[SKIP] user skipped: {vp.name}\")\n",
    "#         continue\n",
    "#     else:\n",
    "#         # default fallback: if adaptation failed and not redrawn, use reference ROIs\n",
    "#         rows = adapted if adapted is not None else ref_rows\n",
    "#         reason = \"fallback_to_reference\" if adapted is None else \"accepted_adapted_default\"\n",
    "\n",
    "#     save_rois_csv(Path(out_csv), rows)\n",
    "#     print(f\"Saved ROIs -> {out_csv}  ({reason})\")\n",
    "#     adapted_summary.append({\"video\": str(vp), \"roi_csv\": out_csv, \"how\": reason})\n",
    "\n",
    "# pd.DataFrame(adapted_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "562b46f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Using ffmpeg at: c:\\Users\\shahd\\OneDrive\\Documents\\GitHub\\mice-maze\\.venv\\lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win-x86_64-v7.1.exe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['c:\\\\Users\\\\shahd\\\\OneDrive\\\\Documents\\\\GitHub\\\\mice-maze\\\\.venv\\\\lib\\\\site-packages\\\\imageio_ffmpeg\\\\binaries\\\\ffmpeg-win-x86_64-v7.1.exe', '-version'], returncode=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install & point to a working ffmpeg binary for THIS kernel\n",
    "%pip install -q imageio-ffmpeg\n",
    "\n",
    "import os, imageio_ffmpeg, shutil, subprocess\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "print(\"Using ffmpeg at:\", os.environ[\"IMAGEIO_FFMPEG_EXE\"])\n",
    "\n",
    "# sanity check\n",
    "subprocess.run([os.environ[\"IMAGEIO_FFMPEG_EXE\"], \"-version\"], check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d120cbba",
   "metadata": {},
   "source": [
    "This script relies on the rois.csv for every video to segment the trials based on the same logic of simplermaze (left e2 after e1 == entered maze == trial starts; ledt e1 after e2 == left maze == trial ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f802622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, subprocess\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "\n",
    "# ---------- ffmpeg ----------\n",
    "def ffmpeg_bin():\n",
    "    return os.environ.get(\"IMAGEIO_FFMPEG_EXE\") or \"ffmpeg\"\n",
    "\n",
    "def ensure_ffmpeg():\n",
    "    exe = ffmpeg_bin()\n",
    "    ok = (Path(exe).exists() if (\":\" in exe or exe.endswith(\".exe\")) else shutil.which(exe) is not None)\n",
    "    if not ok:\n",
    "        raise RuntimeError(f\"ffmpeg not found at '{exe}'. Install ffmpeg or set IMAGEIO_FFMPEG_EXE.\")\n",
    "\n",
    "# ---------- small utils ----------\n",
    "def _grab(frame, r):\n",
    "    return frame[r[\"ystart\"]:r[\"ystart\"]+r[\"ylen\"], r[\"xstart\"]:r[\"xstart\"]+r[\"xlen\"]]\n",
    "\n",
    "def compute_roi_baselines(cap, rois: Dict[str,Dict[str,int]], num_frames=10, thresh_value=160):\n",
    "    thresholds = {k: 0.0 for k in rois}; n = 0\n",
    "    pos = int(cap.get(cv.CAP_PROP_POS_FRAMES))\n",
    "    for _ in range(num_frames):\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) if frame.ndim == 3 else frame\n",
    "        _, bw = cv.threshold(gray, thresh_value, 255, cv.THRESH_BINARY)\n",
    "        for name, rect in rois.items():\n",
    "            thresholds[name] += float(np.sum(_grab(bw, rect)))\n",
    "        n += 1\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, pos)\n",
    "    if n == 0:\n",
    "        raise RuntimeError(\"Could not read frames to compute baselines.\")\n",
    "    for k in thresholds: thresholds[k] /= n\n",
    "    return thresholds\n",
    "\n",
    "def detect_bouts_by_entrances(\n",
    "    video_path: str,\n",
    "    rois_csv: str,\n",
    "    thresh_value: int = 160,\n",
    "    threshold_factor: float = 0.5,\n",
    "    min_duration_s: float = 0.4,\n",
    "    merge_gap_s: float = 0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build bouts using entrance logic:\n",
    "      - leave entrance1 then leave entrance2  => ENTER\n",
    "      - leave entrance2 then leave entrance1  => EXIT\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(rois_csv)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    rois = {str(n).lower(): {\"xstart\":int(x), \"ystart\":int(y), \"xlen\":int(w), \"ylen\":int(h)}\n",
    "            for n,x,y,w,h in df[[\"name\",\"x\",\"y\",\"w\",\"h\"]].itertuples(index=False, name=None)}\n",
    "    if \"entrance1\" not in rois or \"entrance2\" not in rois:\n",
    "        raise ValueError(\"ROIs must include 'entrance1' and 'entrance2'.\")\n",
    "\n",
    "    # open video\n",
    "    for backend in (cv.CAP_MSMF, cv.CAP_FFMPEG, cv.CAP_DSHOW, cv.CAP_ANY):\n",
    "        cap = cv.VideoCapture(str(video_path), backend)\n",
    "        ok, _ = cap.read()\n",
    "        if ok: \n",
    "            cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "            break\n",
    "        try: cap.release()\n",
    "        except: pass\n",
    "        cap = None\n",
    "    if cap is None:\n",
    "        raise FileNotFoundError(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    fps = cap.get(cv.CAP_PROP_FPS) or 0.0\n",
    "    if fps <= 1e-3: fps = 30.0\n",
    "    total_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT)) or None\n",
    "\n",
    "    baselines = compute_roi_baselines(cap, rois, num_frames=10, thresh_value=thresh_value)\n",
    "    def occupied(bw, name):\n",
    "        return (np.sum(_grab(bw, rois[name])) < baselines[name] * threshold_factor)\n",
    "\n",
    "    ent1_prev = False; ent2_prev = False\n",
    "    hasLeft1 = False; hasLeft2 = False\n",
    "    entered = False\n",
    "    bouts = []\n",
    "    cur_start = None\n",
    "\n",
    "    frame_idx = 0\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) if frame.ndim == 3 else frame\n",
    "        _, bw = cv.threshold(gray, thresh_value, 255, cv.THRESH_BINARY)\n",
    "\n",
    "        e1_now = occupied(bw, \"entrance1\")\n",
    "        e2_now = occupied(bw, \"entrance2\")\n",
    "\n",
    "        left1 = (not e1_now) and ent1_prev\n",
    "        left2 = (not e2_now) and ent2_prev\n",
    "\n",
    "        if left1:\n",
    "            hasLeft1 = True\n",
    "            if hasLeft2 and entered:\n",
    "                # EXIT (sequence 2->1)\n",
    "                end_s = frame_idx / fps\n",
    "                if cur_start is not None:\n",
    "                    bouts.append((cur_start, end_s))\n",
    "                cur_start = None\n",
    "                entered = False\n",
    "                hasLeft1 = hasLeft2 = False\n",
    "\n",
    "        if left2:\n",
    "            hasLeft2 = True\n",
    "            if hasLeft1 and not entered:\n",
    "                # ENTER (sequence 1->2)\n",
    "                cur_start = frame_idx / fps\n",
    "                entered = True\n",
    "\n",
    "        ent1_prev, ent2_prev = e1_now, e2_now\n",
    "        frame_idx += 1\n",
    "\n",
    "    if entered and cur_start is not None:\n",
    "        end_s = (total_frames / fps) if total_frames else (frame_idx / fps)\n",
    "        bouts.append((cur_start, end_s))\n",
    "    cap.release()\n",
    "\n",
    "    # merge short gaps & drop tiny bouts\n",
    "    if not bouts:\n",
    "        return []\n",
    "    merged = []\n",
    "    s0, e0 = bouts[0]\n",
    "    for s, e in bouts[1:]:\n",
    "        if s - e0 <= merge_gap_s:\n",
    "            e0 = e\n",
    "        else:\n",
    "            merged.append((s0, e0)); s0, e0 = s, e\n",
    "    merged.append((s0, e0))\n",
    "    return [(s, e) for (s, e) in merged if (e - s) >= min_duration_s]\n",
    "\n",
    "def cut_segment_ffmpeg(video, start_s, end_s, out_path, reencode=True):\n",
    "    ensure_ffmpeg()\n",
    "    out_path = Path(out_path); out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if reencode:\n",
    "        cmd = [\n",
    "            ffmpeg_bin(), \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "            \"-ss\", f\"{start_s:.3f}\", \"-t\", f\"{max(0.0, end_s - start_s):.3f}\",\n",
    "            \"-i\", str(video),\n",
    "            \"-map\", \"0:v:0?\", \"-c:v\", \"libx264\", \"-preset\", \"veryfast\", \"-crf\", \"18\",\n",
    "            \"-movflags\", \"+faststart\", \"-reset_timestamps\", \"1\", str(out_path)\n",
    "        ]\n",
    "    else:\n",
    "        cmd = [\n",
    "            ffmpeg_bin(), \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "            \"-ss\", f\"{start_s:.3f}\", \"-to\", f\"{end_s:.3f}\",\n",
    "            \"-i\", str(video),\n",
    "            \"-map\", \"0:v:0?\", \"-c\", \"copy\",\n",
    "            \"-movflags\", \"+faststart\", \"-reset_timestamps\", \"1\", str(out_path)\n",
    "        ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "def segment_video_by_detected_bouts(\n",
    "    video_path: str,\n",
    "    rois_csv: str,\n",
    "    outdir: str,\n",
    "    base_label: str,\n",
    "    padding_s: float,\n",
    "    reencode: bool,\n",
    "    thresh_value: int,\n",
    "    threshold_factor: float,\n",
    "    min_duration_s: float,\n",
    "    merge_gap_s: float,\n",
    "):\n",
    "    bouts = detect_bouts_by_entrances(\n",
    "        video_path, rois_csv,\n",
    "        thresh_value=thresh_value,\n",
    "        threshold_factor=threshold_factor,\n",
    "        min_duration_s=min_duration_s,\n",
    "        merge_gap_s=merge_gap_s,\n",
    "    )\n",
    "    segments = []\n",
    "    for i, (s, e) in enumerate(bouts):\n",
    "        s2 = max(0.0, s - padding_s)\n",
    "        e2 = max(s2, e + padding_s)\n",
    "        out_name = f\"{base_label}_trial_{i:03d}.mp4\"\n",
    "        out_path = Path(outdir) / out_name\n",
    "        cut_segment_ffmpeg(video_path, s2, e2, out_path, reencode=reencode)\n",
    "        segments.append({\"trial_index\": i, \"start_s\": s, \"end_s\": e, \"path\": str(out_path)})\n",
    "    return segments\n",
    "\n",
    "def update_trials_csv_with_paths(trials_csv: str, segments, column_name=\"video_segment_path\", inplace=False):\n",
    "    trials_csv = Path(trials_csv).resolve()\n",
    "    df = pd.read_csv(trials_csv)\n",
    "    paths = [seg[\"path\"] for seg in segments]\n",
    "    n = min(len(df), len(paths))\n",
    "    if column_name not in df.columns:\n",
    "        df[column_name] = pd.NA\n",
    "    df.loc[:n-1, column_name] = paths[:n]\n",
    "    updated = trials_csv if inplace else trials_csv.with_name(trials_csv.stem + \"_with_segments_detected.csv\")\n",
    "    df.to_csv(updated, index=False)\n",
    "    return str(updated), n, len(paths), len(df)\n",
    "\n",
    "def build_outdir(video_path: Path):\n",
    "    # put per-video segments under: <video_dir>/segments_detected/<video_stem>/\n",
    "    return video_path.parent / \"segments_detected\" / video_path.stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a1980a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# 1) Override the output folder to the legacy \"segments\" (next to the video)\n",
    "def build_outdir(video_path: Path) -> Path:\n",
    "    return video_path.parent / \"segments\"\n",
    "\n",
    "# 2) Helper: remove ONLY old trial clips for this video (keeps other files intact)\n",
    "def purge_old_segments_for_video(video_path: Path, dry_run=False) -> int:\n",
    "    outdir = build_outdir(video_path)\n",
    "    if not outdir.exists():\n",
    "        return 0\n",
    "    pattern = f\"{video_path.stem}_trial_*.mp4\"\n",
    "    to_delete = list(outdir.glob(pattern))\n",
    "    if dry_run:\n",
    "        print(f\"[dry-run] would delete {len(to_delete)} in {outdir} (pattern {pattern})\")\n",
    "        for p in to_delete[:5]:\n",
    "            print(\" \", p.name)\n",
    "        return len(to_delete)\n",
    "    # delete\n",
    "    for p in to_delete:\n",
    "        try:\n",
    "            p.unlink()\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] could not delete {p.name}: {e}\")\n",
    "    return len(to_delete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61cd4557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Fast first-frame helpers (define once per kernel)\n",
    "\n",
    "# If you don't already have it in THIS kernel:\n",
    "%pip install -q imageio-ffmpeg\n",
    "\n",
    "import os, subprocess\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "import imageio_ffmpeg\n",
    "\n",
    "# Prefer a known-good ffmpeg binary (bundled by imageio-ffmpeg)\n",
    "os.environ.setdefault(\"IMAGEIO_FFMPEG_EXE\", imageio_ffmpeg.get_ffmpeg_exe())\n",
    "\n",
    "def ffmpeg_bin():\n",
    "    \"\"\"Return the ffmpeg executable path (env var if set, else 'ffmpeg').\"\"\"\n",
    "    return os.environ.get(\"IMAGEIO_FFMPEG_EXE\") or \"ffmpeg\"\n",
    "\n",
    "def open_video_fast(path: str):\n",
    "    \"\"\"Try FFmpeg first (usually fastest), then other OpenCV backends.\"\"\"\n",
    "    for backend in (cv.CAP_FFMPEG, cv.CAP_MSMF, cv.CAP_DSHOW, cv.CAP_ANY):\n",
    "        cap = cv.VideoCapture(path, backend)\n",
    "        ok, frame = cap.read()\n",
    "        if ok and frame is not None:\n",
    "            cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "            return cap\n",
    "        try: cap.release()\n",
    "        except Exception: pass\n",
    "    return None\n",
    "\n",
    "def grab_first_frame_fast(video_path: str):\n",
    "    \"\"\"Open with a fast backend and grab frame 0 (OpenCV only).\"\"\"\n",
    "    cap = open_video_fast(video_path)\n",
    "    if cap is None:\n",
    "        return None\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    return frame if ok else None\n",
    "\n",
    "def grab_first_frame_ffmpeg(video_path: str):\n",
    "    \"\"\"\n",
    "    Snapshot the first frame via ffmpeg to a temp JPEG, read with OpenCV,\n",
    "    then clean up. Falls back to grab_first_frame_fast on error.\n",
    "    \"\"\"\n",
    "    exe = ffmpeg_bin()\n",
    "    tmp = Path(video_path).with_suffix(\".firstframe.jpg\")\n",
    "    try:\n",
    "        cmd = [\n",
    "            exe, \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "            \"-nostdin\", \"-y\",\n",
    "            \"-ss\", \"0\", \"-i\", video_path,\n",
    "            \"-frames:v\", \"1\", str(tmp)\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True)\n",
    "        frame = cv.imread(str(tmp), cv.IMREAD_COLOR)\n",
    "        try:\n",
    "            tmp.unlink()  # delete the temp file\n",
    "        except Exception:\n",
    "            pass\n",
    "        return frame\n",
    "    except Exception:\n",
    "        return grab_first_frame_fast(video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15e977",
   "metadata": {},
   "source": [
    "this cell will run the segmentation so if we don't want to rerun the segmentation, I'm going to comment this out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4d44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[roi] using 6357_2024-08-27_13_05_19s3.5_rois.csv\n",
      "[clean] removed 54 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\2024-08-27_13_05_196357session3.5\\segments\n",
      "[csv] mouse6357_session3.5_trial_info.csv: filled 56/57 rows -> mouse6357_session3.5_trial_info.csv\n",
      "[roi] using 6357_2024-08-28_11_58_14s3.6_rois.csv\n",
      "[clean] removed 84 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\2024-08-28_11_58_146357session3.6\\segments\n",
      "[csv] mouse6357_session3.6_trial_info.csv: filled 67/67 rows -> mouse6357_session3.6_trial_info.csv\n",
      "[roi] using 6357_2024-08-29_10_23_02s3.7_rois.csv\n",
      "[clean] removed 63 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\2024-08-29_10_23_026357session3.7\\segments\n",
      "[csv] mouse6357_session3.7_trial_info.csv: filled 66/69 rows -> mouse6357_session3.7_trial_info.csv\n",
      "[roi] using 6357_2024-08-30_10_07_55s3.8_rois.csv\n",
      "[clean] removed 56 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\2024-08-30_10_07_556357session3.8\\segments\n",
      "[csv] mouse6357_session3.8_trial_info.csv: filled 55/73 rows -> mouse6357_session3.8_trial_info.csv\n",
      "[roi] using 6357_2024-08-15_11_23_10_rois.csv\n",
      "[clean] removed 41 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\habituation\\segments\n",
      "[csv] mouse6357_session1.1_trial_info.csv: filled 47/50 rows -> mouse6357_session1.1_trial_info.csv\n",
      "[roi] using 6359_2024-08-27_14_08_35s3.5_rois.csv\n",
      "[clean] removed 55 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6359\\2024-08-27_14_08_356359session3.5\\segments\n",
      "[csv] mouse6359_session3.5_trial_info.csv: filled 57/64 rows -> mouse6359_session3.5_trial_info.csv\n",
      "[roi] using 6359_2024-08-28_13_28_27s3.6_rois.csv\n",
      "[clean] removed 70 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6359\\2024-08-28_13_28_276359session3.6\\segments\n",
      "[csv] mouse6359_session3.6_trial_info.csv: filled 80/96 rows -> mouse6359_session3.6_trial_info.csv\n",
      "[roi] using 6359_2024-08-29_11_39_28s3.7_rois.csv\n",
      "[clean] removed 64 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6359\\2024-08-29_11_39_286359session3.7\\segments\n",
      "[csv] mouse6359_session3.7_trial_info.csv: filled 64/69 rows -> mouse6359_session3.7_trial_info.csv\n",
      "[roi] using 6359_2024-08-30_11_28_10s3.8_rois.csv\n",
      "[clean] removed 58 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6359\\2024-08-30_11_28_106359session3.8\\segments\n",
      "[csv] mouse6359_session3.8_trial_info.csv: filled 63/71 rows -> mouse6359_session3.8_trial_info.csv\n",
      "[roi] using 6359_2024-08-15_14_05_08_rois.csv\n",
      "[clean] removed 40 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6359\\habituation\\segments\n",
      "[csv] mouse6359_session1.1_trial_info.csv: filled 41/41 rows -> mouse6359_session1.1_trial_info.csv\n",
      "\n",
      "DONE. Replaced segments for: 10 sessions\n"
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# # If you skipped the progress/timing wrappers earlier, this will still work.\n",
    "# # Make sure ffmpeg is available (IMAGEIO_FFMPEG_EXE set, or ffmpeg on PATH).\n",
    "\n",
    "# summaries = []\n",
    "# ref_rows = load_rois_long(REF_ROIS_CSV)  # from your earlier draw cell\n",
    "\n",
    "# for trials_csv, video in csv_video.items():\n",
    "#     vp = Path(video).resolve()\n",
    "#     tp = Path(trials_csv).resolve()\n",
    "#     if not vp.exists():\n",
    "#         print(f\"[SKIP] Video not found: {vp}\"); continue\n",
    "#     if not tp.exists():\n",
    "#         print(f\"[SKIP] CSV not found: {tp}\"); continue\n",
    "\n",
    "#     # per-video ROI file (created earlier by your adapt step; if missing, we try quick adapt/fallback)\n",
    "#     rois_csv = vp.with_suffix(\"\").as_posix() + \"_rois.csv\"\n",
    "#     if not Path(rois_csv).exists():\n",
    "#         # QUICK auto-adapt (no GUI); fallback to reference ROIs if needed\n",
    "#         cur_frame = grab_first_frame_ffmpeg(str(vp)) or grab_first_frame_fast(str(vp))\n",
    "#         if cur_frame is None:\n",
    "#             print(f\"[SKIP] Cannot open video for ROI: {vp}\"); continue\n",
    "#         ref_frame = grab_first_frame_ffmpeg(first_video) or grab_first_frame_fast(first_video)\n",
    "#         adapted = auto_rois_from_reference(cur_frame, ref_frame, ref_rows, pyr_scale=PYR_SCALE)\n",
    "#         rows = adapted if adapted is not None else ref_rows\n",
    "#         save_rois_csv(Path(rois_csv), rows)\n",
    "#         print(f\"[roi] {'adapted' if adapted is not None else 'fallback ref'} -> {Path(rois_csv).name}\")\n",
    "#     else:\n",
    "#         print(f\"[roi] using {Path(rois_csv).name}\")\n",
    "\n",
    "#     # purge ONLY this video's old CSV-based clips in legacy segments/\n",
    "#     deleted = purge_old_segments_for_video(vp, dry_run=False)\n",
    "#     if deleted:\n",
    "#         print(f\"[clean] removed {deleted} old segments in {build_outdir(vp)}\")\n",
    "\n",
    "#     # cut NEW vision-logic segments into the SAME legacy folder\n",
    "#     outdir = build_outdir(vp)\n",
    "#     segs = segment_video_by_detected_bouts(\n",
    "#         video_path=str(vp),\n",
    "#         rois_csv=rois_csv,\n",
    "#         outdir=str(outdir),\n",
    "#         base_label=vp.stem,\n",
    "#         padding_s=0.10,        # adjust if you want more/less context at boundaries\n",
    "#         reencode=True,         # precise cuts; set False for speed (keyframe aligned)\n",
    "#         thresh_value=160,\n",
    "#         threshold_factor=0.6,\n",
    "#         min_duration_s=0.25,\n",
    "#         merge_gap_s=0.20,\n",
    "#     )\n",
    "\n",
    "#     # update the trial CSV to point at THESE new files in legacy segments/\n",
    "#     updated_csv_path, filled, n_segments, n_rows = update_trials_csv_with_paths(\n",
    "#         trials_csv=str(tp),\n",
    "#         segments=segs,\n",
    "#         column_name=\"video_segment_path\",\n",
    "#         inplace=True,          # overwrite the original *_trial_info.csv mapping\n",
    "#     )\n",
    "#     print(f\"[csv] {Path(tp).name}: filled {filled}/{n_rows} rows -> {Path(updated_csv_path).name}\")\n",
    "\n",
    "#     summaries.append({\n",
    "#         \"video\": str(vp),\n",
    "#         \"roi_csv\": rois_csv,\n",
    "#         \"segments_outdir\": str(outdir),\n",
    "#         \"segments_made\": len(segs),\n",
    "#         \"csv_original\": str(tp),\n",
    "#         \"csv_updated\": updated_csv_path,\n",
    "#         \"rows_filled\": filled,\n",
    "#         \"csv_rows\": n_rows\n",
    "#     })\n",
    "\n",
    "# print(\"\\nDONE. Replaced segments for:\", len(summaries), \"sessions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b05acf",
   "metadata": {},
   "source": [
    "here we basically check which parts of the video don't get segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ab58525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse the SAME parameters you used when segmenting\n",
    "# If these globals already exist in your notebook, these lines just read them.\n",
    "THRESH_VALUE    = globals().get(\"THRESH_VALUE\", 160)\n",
    "THRESH_FACTOR   = globals().get(\"THRESH_FACTOR\", 0.50)  # <- must match what you used when cutting\n",
    "MIN_DURATION_S  = globals().get(\"MIN_DURATION_S\", 0.40)\n",
    "MERGE_GAP_S     = globals().get(\"MERGE_GAP_S\", 0.20)\n",
    "PADDING_S       = globals().get(\"PADDING_S\", 0.10)\n",
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "def detect_bouts_same_as_seg_exact(video_path: str, rois_csv: str):\n",
    "    \"\"\"\n",
    "    Call YOUR detect_bouts_by_entrances with the SAME 4 kwargs you used in segmentation.\n",
    "    \"\"\"\n",
    "    if \"detect_bouts_by_entrances\" not in globals():\n",
    "        raise RuntimeError(\"detect_bouts_by_entrances is not defined in this kernel.\")\n",
    "    return detect_bouts_by_entrances(\n",
    "        video_path=video_path,\n",
    "        rois_csv=rois_csv,\n",
    "        thresh_value=THRESH_VALUE,\n",
    "        threshold_factor=THRESH_FACTOR,\n",
    "        min_duration_s=MIN_DURATION_S,\n",
    "        merge_gap_s=MERGE_GAP_S,\n",
    "    )\n",
    "\n",
    "def get_video_duration_seconds(video_path: str) -> float:\n",
    "    \"\"\"OpenCV-only duration (avoids ffprobe).\"\"\"\n",
    "    cap = cv.VideoCapture(str(video_path))\n",
    "    try:\n",
    "        fc  = cap.get(cv.CAP_PROP_FRAME_COUNT) or 0.0\n",
    "        fps = cap.get(cv.CAP_PROP_FPS) or 0.0\n",
    "        return float(fc / fps) if fps and fc else 0.0\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "def merge_intervals(intervals, eps=1e-6):\n",
    "    if not intervals: return []\n",
    "    intervals = sorted((float(s), float(e)) for s, e in intervals if e >= s)\n",
    "    merged=[]; s0,e0 = intervals[0]\n",
    "    for s,e in intervals[1:]:\n",
    "        if s <= e0 + eps: e0 = max(e0, e)\n",
    "        else: merged.append((s0,e0)); s0,e0 = s,e\n",
    "    merged.append((s0,e0))\n",
    "    return merged\n",
    "\n",
    "def invert_intervals(covered, total_duration, eps=1e-6):\n",
    "    T = float(total_duration)\n",
    "    if not covered:\n",
    "        return [(0.0, T)] if T>0 else []\n",
    "    gaps=[]\n",
    "    if covered[0][0] > 0 + eps: gaps.append((0.0, covered[0][0]))\n",
    "    for (s0,e0),(s1,e1) in zip(covered, covered[1:]):\n",
    "        if s1 > e0 + eps: gaps.append((e0, s1))\n",
    "    if covered[-1][1] < T - eps: gaps.append((covered[-1][1], T))\n",
    "    return gaps\n",
    "\n",
    "def to_df_gaps(video_path, gaps, total_duration, covered):\n",
    "    covered_dur = sum(max(0.0, e-s) for s,e in covered)\n",
    "    rows = [{\"gap_index\":i,\n",
    "             \"start_s\":round(float(s),3),\n",
    "             \"end_s\":round(float(e),3),\n",
    "             \"duration_s\":round(float(e-s),3)} for i,(s,e) in enumerate(gaps)]\n",
    "    df = pd.DataFrame(rows)\n",
    "    stats = {\n",
    "        \"video\": str(video_path),\n",
    "        \"total_duration_s\": round(float(total_duration),3),\n",
    "        \"covered_duration_s\": round(float(covered_dur),3),\n",
    "        \"uncovered_duration_s\": round(float(total_duration - covered_dur),3),\n",
    "        \"n_gaps\": int(len(gaps)),\n",
    "        \"coverage_pct\": round(100.0*covered_dur/total_duration, 2) if total_duration>0 else np.nan,\n",
    "    }\n",
    "    return df, stats\n",
    "\n",
    "def build_outdir(video_path: Path) -> Path:\n",
    "    # Same segments folder you already used for clips\n",
    "    return video_path.parent / \"segments\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcc2090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gaps] 6357_2024-08-27_13_05_19s3.5.mp4: coverage=32.22% gaps=55 -> 6357_2024-08-27_13_05_19s3.5_uncovered_gaps.csv\n",
      "[gaps] 6357_2024-08-28_11_58_14s3.6.mp4: coverage=51.09% gaps=89 -> 6357_2024-08-28_11_58_14s3.6_uncovered_gaps.csv\n",
      "[gaps] 6357_2024-08-29_10_23_02s3.7.mp4: coverage=45.99% gaps=65 -> 6357_2024-08-29_10_23_02s3.7_uncovered_gaps.csv\n",
      "[gaps] 6357_2024-08-30_10_07_55s3.8.mp4: coverage=58.95% gaps=53 -> 6357_2024-08-30_10_07_55s3.8_uncovered_gaps.csv\n",
      "[gaps] 6357_2024-08-15_11_23_10.mp4: coverage=39.15% gaps=46 -> 6357_2024-08-15_11_23_10_uncovered_gaps.csv\n",
      "[gaps] 6359_2024-08-27_14_08_35s3.5.mp4: coverage=52.11% gaps=59 -> 6359_2024-08-27_14_08_35s3.5_uncovered_gaps.csv\n",
      "[gaps] 6359_2024-08-28_13_28_27s3.6.mp4: coverage=55.11% gaps=76 -> 6359_2024-08-28_13_28_27s3.6_uncovered_gaps.csv\n",
      "[gaps] 6359_2024-08-29_11_39_28s3.7.mp4: coverage=45.09% gaps=65 -> 6359_2024-08-29_11_39_28s3.7_uncovered_gaps.csv\n",
      "[gaps] 6359_2024-08-30_11_28_10s3.8.mp4: coverage=43.45% gaps=62 -> 6359_2024-08-30_11_28_10s3.8_uncovered_gaps.csv\n",
      "[gaps] 6359_2024-08-15_14_05_08.mp4: coverage=48.51% gaps=42 -> 6359_2024-08-15_14_05_08_uncovered_gaps.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>total_duration_s</th>\n",
       "      <th>covered_duration_s</th>\n",
       "      <th>uncovered_duration_s</th>\n",
       "      <th>n_gaps</th>\n",
       "      <th>coverage_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>3572.867</td>\n",
       "      <td>1151.233</td>\n",
       "      <td>2421.633</td>\n",
       "      <td>55</td>\n",
       "      <td>32.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>5157.233</td>\n",
       "      <td>2018.933</td>\n",
       "      <td>3138.300</td>\n",
       "      <td>46</td>\n",
       "      <td>39.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>3906.867</td>\n",
       "      <td>1697.667</td>\n",
       "      <td>2209.200</td>\n",
       "      <td>62</td>\n",
       "      <td>43.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>3649.067</td>\n",
       "      <td>1645.367</td>\n",
       "      <td>2003.700</td>\n",
       "      <td>65</td>\n",
       "      <td>45.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>4012.867</td>\n",
       "      <td>1845.433</td>\n",
       "      <td>2167.433</td>\n",
       "      <td>65</td>\n",
       "      <td>45.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>3452.100</td>\n",
       "      <td>1674.533</td>\n",
       "      <td>1777.567</td>\n",
       "      <td>42</td>\n",
       "      <td>48.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>5075.300</td>\n",
       "      <td>2593.133</td>\n",
       "      <td>2482.167</td>\n",
       "      <td>89</td>\n",
       "      <td>51.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>3682.633</td>\n",
       "      <td>1919.133</td>\n",
       "      <td>1763.500</td>\n",
       "      <td>59</td>\n",
       "      <td>52.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>3800.733</td>\n",
       "      <td>2094.600</td>\n",
       "      <td>1706.133</td>\n",
       "      <td>76</td>\n",
       "      <td>55.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>4312.233</td>\n",
       "      <td>2542.267</td>\n",
       "      <td>1769.967</td>\n",
       "      <td>53</td>\n",
       "      <td>58.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               video  total_duration_s  \\\n",
       "0  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...          3572.867   \n",
       "4  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...          5157.233   \n",
       "8  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...          3906.867   \n",
       "7  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...          3649.067   \n",
       "2  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...          4012.867   \n",
       "9  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...          3452.100   \n",
       "1  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...          5075.300   \n",
       "5  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...          3682.633   \n",
       "6  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...          3800.733   \n",
       "3  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...          4312.233   \n",
       "\n",
       "   covered_duration_s  uncovered_duration_s  n_gaps  coverage_pct  \n",
       "0            1151.233              2421.633      55         32.22  \n",
       "4            2018.933              3138.300      46         39.15  \n",
       "8            1697.667              2209.200      62         43.45  \n",
       "7            1645.367              2003.700      65         45.09  \n",
       "2            1845.433              2167.433      65         45.99  \n",
       "9            1674.533              1777.567      42         48.51  \n",
       "1            2593.133              2482.167      89         51.09  \n",
       "5            1919.133              1763.500      59         52.11  \n",
       "6            2094.600              1706.133      76         55.11  \n",
       "3            2542.267              1769.967      53         58.95  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary -> C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\segmentation_coverage_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Requires: `csv_video` dict from your notebook\n",
    "all_stats = []\n",
    "\n",
    "for trials_csv, video in list(csv_video.items()):\n",
    "    vp = Path(video).resolve()\n",
    "    tp = Path(trials_csv).resolve()\n",
    "    if not vp.exists():\n",
    "        print(f\"[SKIP] Video not found: {vp}\"); continue\n",
    "\n",
    "    # Must use the per-video ROI file you used when cutting\n",
    "    rois_csv = vp.with_suffix(\"\").as_posix() + \"_rois.csv\"\n",
    "    if not Path(rois_csv).exists():\n",
    "        print(f\"[SKIP] Missing ROIs for {vp.name} -> {rois_csv}\"); continue\n",
    "\n",
    "    # 1) Reuse the EXACT detector + params from segmentation\n",
    "    bouts = detect_bouts_same_as_seg_exact(str(vp), rois_csv)\n",
    "\n",
    "    # 2) Apply the SAME padding you used when cutting\n",
    "    T = get_video_duration_seconds(str(vp))\n",
    "    padded = []\n",
    "    for (s, e) in bouts:\n",
    "        s2 = max(0.0, float(s) - float(PADDING_S))\n",
    "        e2 = min(float(T), max(s2, float(e) + float(PADDING_S)))\n",
    "        padded.append((s2, e2))\n",
    "\n",
    "    # 3) Merge, invert -> gaps\n",
    "    covered = merge_intervals(padded)\n",
    "    gaps    = invert_intervals(covered, T)\n",
    "\n",
    "    # 4) Save per-video gaps CSV next to your segments\n",
    "    outdir = build_outdir(vp); outdir.mkdir(parents=True, exist_ok=True)\n",
    "    gaps_csv = outdir / f\"{vp.stem}_uncovered_gaps.csv\"\n",
    "    df_gaps, stats = to_df_gaps(vp, gaps, T, covered)\n",
    "    df_gaps.to_csv(gaps_csv, index=False)\n",
    "    print(f\"[gaps] {vp.name}: coverage={stats['coverage_pct']}% gaps={len(gaps)} -> {gaps_csv.name}\")\n",
    "\n",
    "    all_stats.append(stats)\n",
    "\n",
    "# 5) Save a global summary (one row per video)\n",
    "summary_df = pd.DataFrame(all_stats).sort_values(\"coverage_pct\", ascending=True)\n",
    "display(summary_df)\n",
    "\n",
    "# Save near the session roots (adjust if you prefer a different location)\n",
    "root_hint = Path(list(csv_video.values())[0]).resolve().parents[1]\n",
    "summary_path = root_hint / \"segmentation_coverage_summary.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(\"Saved summary ->\", summary_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb3249",
   "metadata": {},
   "source": [
    "As a sanity check, I'm going to extrapolate the frames of the segments so that I can determine at which points of the video the segments are (this is to identify mistakes or misdetections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ea9e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# Reuse your existing globals; fallback to the values you said you used for cutting\n",
    "# THRESH_VALUE    = globals().get(\"THRESH_VALUE\",   160)\n",
    "# THRESH_FACTOR   = globals().get(\"THRESH_FACTOR\",  0.50)  # <-- keep this equal to the one used in your cutting cell\n",
    "# MIN_DURATION_S  = globals().get(\"MIN_DURATION_S\", 0.40)\n",
    "# MERGE_GAP_S     = globals().get(\"MERGE_GAP_S\",    0.20)\n",
    "# PADDING_S       = globals().get(\"PADDING_S\",      0.10)\n",
    "\n",
    "def get_fps_and_frames(video_path: str) -> tuple[float, int]:\n",
    "    \"\"\"Return (fps, total_frames). FPS must be > 0; total_frames >= 0.\"\"\"\n",
    "    cap = cv.VideoCapture(str(video_path))\n",
    "    try:\n",
    "        fps = cap.get(cv.CAP_PROP_FPS) or 0.0\n",
    "        fc  = int(cap.get(cv.CAP_PROP_FRAME_COUNT) or 0)\n",
    "    finally:\n",
    "        cap.release()\n",
    "    if fps <= 0:\n",
    "        # very rare, but try a tiny probe\n",
    "        cap = cv.VideoCapture(str(video_path))\n",
    "        try:\n",
    "            ok, _ = cap.read()\n",
    "            fps = cap.get(cv.CAP_PROP_FPS) or 30.0\n",
    "        finally:\n",
    "            cap.release()\n",
    "    return float(fps), int(fc)\n",
    "\n",
    "def sec_to_frame(sec: float, fps: float, clamp: int | None = None) -> int:\n",
    "    \"\"\"Round to nearest frame index (inclusive). Clamp to [0, clamp-1] if clamp is provided.\"\"\"\n",
    "    f = int(round(float(sec) * float(fps)))\n",
    "    if clamp is not None:\n",
    "        f = max(0, min(clamp - 1, f))\n",
    "    return f\n",
    "\n",
    "def frames_merge(intervals: list[tuple[int,int]]) -> list[tuple[int,int]]:\n",
    "    \"\"\"Merge inclusive frame intervals [a,b].\"\"\"\n",
    "    if not intervals: return []\n",
    "    intervals = sorted((int(a), int(b)) for a,b in intervals if b >= a)\n",
    "    merged = []\n",
    "    a0, b0 = intervals[0]\n",
    "    for a,b in intervals[1:]:\n",
    "        if a <= b0 + 1:  # touch/overlap\n",
    "            b0 = max(b0, b)\n",
    "        else:\n",
    "            merged.append((a0,b0))\n",
    "            a0, b0 = a, b\n",
    "    merged.append((a0,b0))\n",
    "    return merged\n",
    "\n",
    "def frames_invert(covered: list[tuple[int,int]], total_frames: int) -> list[tuple[int,int]]:\n",
    "    \"\"\"Return uncovered frame intervals [a,b] inclusive within [0, total_frames-1].\"\"\"\n",
    "    if total_frames <= 0:\n",
    "        return []\n",
    "    if not covered:\n",
    "        return [(0, total_frames - 1)]\n",
    "    gaps = []\n",
    "    # pre-gap\n",
    "    if covered[0][0] > 0:\n",
    "        gaps.append((0, covered[0][0] - 1))\n",
    "    # middle gaps\n",
    "    for (a0,b0),(a1,b1) in zip(covered, covered[1:]):\n",
    "        if a1 > b0 + 1:\n",
    "            gaps.append((b0 + 1, a1 - 1))\n",
    "    # post-gap\n",
    "    if covered[-1][1] < total_frames - 1:\n",
    "        gaps.append((covered[-1][1] + 1, total_frames - 1))\n",
    "    return gaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2350aa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[manifest] 6357_2024-08-27_13_05_19s3.5.mp4: 54 segments -> 6357_2024-08-27_13_05_19s3.5_segments_manifest.csv\n",
      "[manifest] 6357_2024-08-28_11_58_14s3.6.mp4: 89 segments -> 6357_2024-08-28_11_58_14s3.6_segments_manifest.csv\n",
      "[manifest] 6357_2024-08-29_10_23_02s3.7.mp4: 64 segments -> 6357_2024-08-29_10_23_02s3.7_segments_manifest.csv\n",
      "[manifest] 6357_2024-08-30_10_07_55s3.8.mp4: 54 segments -> 6357_2024-08-30_10_07_55s3.8_segments_manifest.csv\n",
      "[manifest] 6357_2024-08-15_11_23_10.mp4: 46 segments -> 6357_2024-08-15_11_23_10_segments_manifest.csv\n",
      "[manifest] 6359_2024-08-27_14_08_35s3.5.mp4: 58 segments -> 6359_2024-08-27_14_08_35s3.5_segments_manifest.csv\n",
      "[manifest] 6359_2024-08-28_13_28_27s3.6.mp4: 76 segments -> 6359_2024-08-28_13_28_27s3.6_segments_manifest.csv\n",
      "[manifest] 6359_2024-08-29_11_39_28s3.7.mp4: 64 segments -> 6359_2024-08-29_11_39_28s3.7_segments_manifest.csv\n",
      "[manifest] 6359_2024-08-30_11_28_10s3.8.mp4: 61 segments -> 6359_2024-08-30_11_28_10s3.8_segments_manifest.csv\n",
      "[manifest] 6359_2024-08-15_14_05_08.mp4: 41 segments -> 6359_2024-08-15_14_05_08_segments_manifest.csv\n"
     ]
    }
   ],
   "source": [
    "def manifest_from_detection(video_path: str, rois_csv: str,\n",
    "                            thresh_value: int = THRESH_VALUE,\n",
    "                            threshold_factor: float = THRESH_FACTOR,\n",
    "                            min_duration_s: float = MIN_DURATION_S,\n",
    "                            merge_gap_s: float = MERGE_GAP_S,\n",
    "                            padding_s: float = PADDING_S) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with columns:\n",
    "      trial_index, start_s, end_s, start_frame, end_frame, fps, total_frames, expected_clip_path\n",
    "    No cutting; just detection + conversion to frames with padding.\n",
    "    \"\"\"\n",
    "    # --- 1) detect bouts using YOUR segmentation detector ---\n",
    "    if \"detect_bouts_by_entrances\" not in globals():\n",
    "        raise RuntimeError(\"detect_bouts_by_entrances is not defined in this kernel.\")\n",
    "    bouts = detect_bouts_by_entrances(\n",
    "        video_path=video_path,\n",
    "        rois_csv=rois_csv,\n",
    "        thresh_value=thresh_value,\n",
    "        threshold_factor=threshold_factor,\n",
    "        min_duration_s=min_duration_s,\n",
    "        merge_gap_s=merge_gap_s,\n",
    "    )\n",
    "\n",
    "    # --- 2) fps/frame count ---\n",
    "    fps, total_frames = get_fps_and_frames(video_path)\n",
    "    duration_s = total_frames / fps if fps > 0 else 0.0\n",
    "\n",
    "    # --- 3) apply padding in seconds; convert to inclusive frames ---\n",
    "    padded_secs = []\n",
    "    for s, e in bouts:\n",
    "        s2 = max(0.0, float(s) - float(padding_s))\n",
    "        e2 = min(duration_s, max(s2, float(e) + float(padding_s)))\n",
    "        padded_secs.append((s2, e2))\n",
    "\n",
    "    rows = []\n",
    "    base = Path(video_path)\n",
    "    outdir = base.parent / \"segments\"\n",
    "    for i, (s, e) in enumerate(padded_secs):\n",
    "        f0 = sec_to_frame(s, fps, clamp=total_frames)\n",
    "        # inclusive end frame: last frame whose timestamp < e (rounding to nearest)\n",
    "        f1 = sec_to_frame(e, fps, clamp=total_frames)\n",
    "        f1 = max(f0, min(total_frames - 1, f1))  # ensure inclusive & within bounds\n",
    "        expected_name = f\"{base.stem}_trial_{i:03d}.mp4\"\n",
    "        rows.append({\n",
    "            \"trial_index\": i,\n",
    "            \"start_s\": round(s, 3),\n",
    "            \"end_s\": round(e, 3),\n",
    "            \"start_frame\": int(f0),\n",
    "            \"end_frame\": int(f1),\n",
    "            \"fps\": float(fps),\n",
    "            \"total_frames\": int(total_frames),\n",
    "            \"expected_clip_path\": str(outdir / expected_name),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---- Batch over your csv_video dict; write one manifest per video ----\n",
    "manifests = []\n",
    "for trials_csv, video in list(csv_video.items()):\n",
    "    vp = Path(video).resolve()\n",
    "    if not vp.exists():\n",
    "        print(f\"[SKIP] missing video: {vp}\")\n",
    "        continue\n",
    "    rois_csv = vp.with_suffix(\"\").as_posix() + \"_rois.csv\"\n",
    "    if not Path(rois_csv).exists():\n",
    "        print(f\"[SKIP] missing ROI file for {vp.name}: {rois_csv}\")\n",
    "        continue\n",
    "\n",
    "    df = manifest_from_detection(str(vp), rois_csv,\n",
    "                                 thresh_value=THRESH_VALUE,\n",
    "                                 threshold_factor=THRESH_FACTOR,\n",
    "                                 min_duration_s=MIN_DURATION_S,\n",
    "                                 merge_gap_s=MERGE_GAP_S,\n",
    "                                 padding_s=PADDING_S)\n",
    "    # Save next to segments (non-destructive)\n",
    "    outdir = vp.parent / \"segments\"\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    manifest_path = outdir / f\"{vp.stem}_segments_manifest.csv\"\n",
    "    df.to_csv(manifest_path, index=False)\n",
    "    print(f\"[manifest] {vp.name}: {len(df)} segments -> {manifest_path.name}\")\n",
    "    manifests.append({\"video\": str(vp), \"manifest\": str(manifest_path), \"segments\": len(df)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6624a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gaps] 6357_2024-08-27_13_05_19s3.5.mp4: 55 gaps -> 6357_2024-08-27_13_05_19s3.5_uncovered_gaps_by_frames.csv\n",
      "[gaps] 6357_2024-08-28_11_58_14s3.6.mp4: 89 gaps -> 6357_2024-08-28_11_58_14s3.6_uncovered_gaps_by_frames.csv\n",
      "[gaps] 6357_2024-08-29_10_23_02s3.7.mp4: 65 gaps -> 6357_2024-08-29_10_23_02s3.7_uncovered_gaps_by_frames.csv\n",
      "[gaps] 6357_2024-08-30_10_07_55s3.8.mp4: 53 gaps -> 6357_2024-08-30_10_07_55s3.8_uncovered_gaps_by_frames.csv\n",
      "[gaps] 6357_2024-08-15_11_23_10.mp4: 46 gaps -> 6357_2024-08-15_11_23_10_uncovered_gaps_by_frames.csv\n",
      "[gaps] 6359_2024-08-27_14_08_35s3.5.mp4: 59 gaps -> 6359_2024-08-27_14_08_35s3.5_uncovered_gaps_by_frames.csv\n",
      "[gaps] 6359_2024-08-28_13_28_27s3.6.mp4: 76 gaps -> 6359_2024-08-28_13_28_27s3.6_uncovered_gaps_by_frames.csv\n",
      "[gaps] 6359_2024-08-29_11_39_28s3.7.mp4: 65 gaps -> 6359_2024-08-29_11_39_28s3.7_uncovered_gaps_by_frames.csv\n",
      "[gaps] 6359_2024-08-30_11_28_10s3.8.mp4: 61 gaps -> 6359_2024-08-30_11_28_10s3.8_uncovered_gaps_by_frames.csv\n",
      "[gaps] 6359_2024-08-15_14_05_08.mp4: 42 gaps -> 6359_2024-08-15_14_05_08_uncovered_gaps_by_frames.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>total_frames</th>\n",
       "      <th>covered_frames</th>\n",
       "      <th>uncovered_frames</th>\n",
       "      <th>coverage_pct</th>\n",
       "      <th>segments</th>\n",
       "      <th>manifest_csv</th>\n",
       "      <th>gaps_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6357_2024-08-27_13_05_19s3.5.mp4</td>\n",
       "      <td>107186</td>\n",
       "      <td>34591</td>\n",
       "      <td>72595</td>\n",
       "      <td>32.27</td>\n",
       "      <td>54</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6357_2024-08-15_11_23_10.mp4</td>\n",
       "      <td>154717</td>\n",
       "      <td>60613</td>\n",
       "      <td>94104</td>\n",
       "      <td>39.18</td>\n",
       "      <td>46</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6359_2024-08-30_11_28_10s3.8.mp4</td>\n",
       "      <td>117206</td>\n",
       "      <td>50991</td>\n",
       "      <td>66215</td>\n",
       "      <td>43.51</td>\n",
       "      <td>61</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6359_2024-08-29_11_39_28s3.7.mp4</td>\n",
       "      <td>109472</td>\n",
       "      <td>49425</td>\n",
       "      <td>60047</td>\n",
       "      <td>45.15</td>\n",
       "      <td>64</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6357_2024-08-29_10_23_02s3.7.mp4</td>\n",
       "      <td>120386</td>\n",
       "      <td>55427</td>\n",
       "      <td>64959</td>\n",
       "      <td>46.04</td>\n",
       "      <td>64</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6359_2024-08-15_14_05_08.mp4</td>\n",
       "      <td>103563</td>\n",
       "      <td>50277</td>\n",
       "      <td>53286</td>\n",
       "      <td>48.55</td>\n",
       "      <td>41</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6357_2024-08-28_11_58_14s3.6.mp4</td>\n",
       "      <td>152259</td>\n",
       "      <td>77882</td>\n",
       "      <td>74377</td>\n",
       "      <td>51.15</td>\n",
       "      <td>89</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6359_2024-08-27_14_08_35s3.5.mp4</td>\n",
       "      <td>110479</td>\n",
       "      <td>57632</td>\n",
       "      <td>52847</td>\n",
       "      <td>52.17</td>\n",
       "      <td>58</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6359_2024-08-28_13_28_27s3.6.mp4</td>\n",
       "      <td>114022</td>\n",
       "      <td>62913</td>\n",
       "      <td>51109</td>\n",
       "      <td>55.18</td>\n",
       "      <td>76</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6357_2024-08-30_10_07_55s3.8.mp4</td>\n",
       "      <td>129367</td>\n",
       "      <td>76320</td>\n",
       "      <td>53047</td>\n",
       "      <td>58.99</td>\n",
       "      <td>54</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              video  total_frames  covered_frames  \\\n",
       "0  6357_2024-08-27_13_05_19s3.5.mp4        107186           34591   \n",
       "4      6357_2024-08-15_11_23_10.mp4        154717           60613   \n",
       "8  6359_2024-08-30_11_28_10s3.8.mp4        117206           50991   \n",
       "7  6359_2024-08-29_11_39_28s3.7.mp4        109472           49425   \n",
       "2  6357_2024-08-29_10_23_02s3.7.mp4        120386           55427   \n",
       "9      6359_2024-08-15_14_05_08.mp4        103563           50277   \n",
       "1  6357_2024-08-28_11_58_14s3.6.mp4        152259           77882   \n",
       "5  6359_2024-08-27_14_08_35s3.5.mp4        110479           57632   \n",
       "6  6359_2024-08-28_13_28_27s3.6.mp4        114022           62913   \n",
       "3  6357_2024-08-30_10_07_55s3.8.mp4        129367           76320   \n",
       "\n",
       "   uncovered_frames  coverage_pct  segments  \\\n",
       "0             72595         32.27        54   \n",
       "4             94104         39.18        46   \n",
       "8             66215         43.51        61   \n",
       "7             60047         45.15        64   \n",
       "2             64959         46.04        64   \n",
       "9             53286         48.55        41   \n",
       "1             74377         51.15        89   \n",
       "5             52847         52.17        58   \n",
       "6             51109         55.18        76   \n",
       "3             53047         58.99        54   \n",
       "\n",
       "                                        manifest_csv  \\\n",
       "0  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "4  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "8  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "7  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "2  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "9  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "1  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "5  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "6  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "3  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "\n",
       "                                            gaps_csv  \n",
       "0  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...  \n",
       "4  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...  \n",
       "8  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...  \n",
       "7  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...  \n",
       "2  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...  \n",
       "9  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...  \n",
       "1  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...  \n",
       "5  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...  \n",
       "6  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...  \n",
       "3  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = []\n",
    "\n",
    "for rec in manifests:\n",
    "    vp = Path(rec[\"video\"])\n",
    "    manifest_path = Path(rec[\"manifest\"])\n",
    "    df = pd.read_csv(manifest_path)\n",
    "\n",
    "    # If no segments, whole video is a gap\n",
    "    if df.empty:\n",
    "        fps, total_frames = get_fps_and_frames(str(vp))\n",
    "        gaps_f = [(0, total_frames - 1)] if total_frames > 0 else []\n",
    "        gaps_s = [(0.0, total_frames / fps)] if fps > 0 else []\n",
    "    else:\n",
    "        fps = float(df[\"fps\"].iloc[0])\n",
    "        total_frames = int(df[\"total_frames\"].iloc[0])\n",
    "\n",
    "        # Covered, in inclusive frames\n",
    "        covered_f = frames_merge([(int(a), int(b)) for a,b in df[[\"start_frame\",\"end_frame\"]].itertuples(index=False, name=None)])\n",
    "        gaps_f = frames_invert(covered_f, total_frames)\n",
    "\n",
    "    # Build and save gaps CSV (both frames and seconds)\n",
    "    gaps_rows = []\n",
    "    for i, (fa, fb) in enumerate(gaps_f):\n",
    "        sa = fa / fps if fps > 0 else float('nan')\n",
    "        sb = (fb + 1) / fps if fps > 0 else float('nan')  # end is inclusive frame -> end time is (fb+1)/fps\n",
    "        gaps_rows.append({\n",
    "            \"gap_index\": i,\n",
    "            \"start_frame\": int(fa),\n",
    "            \"end_frame\": int(fb),\n",
    "            \"frames\": int(fb - fa + 1),\n",
    "            \"start_s\": round(sa, 3),\n",
    "            \"end_s\": round(sb, 3),\n",
    "            \"duration_s\": round(sb - sa, 3) if (not math.isnan(sa) and not math.isnan(sb)) else float('nan'),\n",
    "        })\n",
    "    df_gaps = pd.DataFrame(gaps_rows)\n",
    "\n",
    "    outdir = vp.parent / \"segments\"\n",
    "    gaps_path = outdir / f\"{vp.stem}_uncovered_gaps_by_frames.csv\"\n",
    "    df_gaps.to_csv(gaps_path, index=False)\n",
    "    print(f\"[gaps] {vp.name}: {len(df_gaps)} gaps -> {gaps_path.name}\")\n",
    "\n",
    "    # Per-video coverage stats\n",
    "    covered_frames = 0\n",
    "    if not df.empty:\n",
    "        for a,b in covered_f:\n",
    "            covered_frames += (b - a + 1)\n",
    "    coverage = 100.0 * covered_frames / total_frames if total_frames > 0 else float('nan')\n",
    "\n",
    "    summary.append({\n",
    "        \"video\": vp.name,\n",
    "        \"total_frames\": total_frames,\n",
    "        \"covered_frames\": covered_frames,\n",
    "        \"uncovered_frames\": max(0, total_frames - covered_frames),\n",
    "        \"coverage_pct\": round(coverage, 2),\n",
    "        \"segments\": int(rec[\"segments\"]),\n",
    "        \"manifest_csv\": str(manifest_path),\n",
    "        \"gaps_csv\": str(gaps_path),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary).sort_values(\"coverage_pct\", ascending=True)\n",
    "display(summary_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
