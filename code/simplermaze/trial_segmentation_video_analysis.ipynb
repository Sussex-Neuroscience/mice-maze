{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76170361",
   "metadata": {},
   "source": [
    "# Trial segmentation script\n",
    "\n",
    "This notebook is intended for the breakdown, classification and analysis of the behavioural states shown in the video, starting from a trial segmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2464a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\shahd\\onedrive\\documents\\github\\mice-maze\\.venv\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shahd\\onedrive\\documents\\github\\mice-maze\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shahd\\onedrive\\documents\\github\\mice-maze\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shahd\\onedrive\\documents\\github\\mice-maze\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shahd\\onedrive\\documents\\github\\mice-maze\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.3 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.7/11.3 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.3/11.3 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.0/11.3 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 11.8 MB/s  0:00:00\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-2.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#uncomment and run if there are issues with the version of the dependencies\n",
    "#  %pip uninstall -y pandas numpy\n",
    "# %pip install --upgrade --force-reinstall \"numpy<2\"\n",
    "# %pip install --upgrade --force-reinstall opencv-python\n",
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce349f8",
   "metadata": {},
   "source": [
    "- `trial segmentation` takes the output of simplerCode.py (video + .csv), and segments the video based on mouse entry and exit times in the video rather than the .csv\n",
    "- we then will manually sort the trials into `exploitative`, `explorative` and `nest`\n",
    "- extract speed and trajectories per trial\n",
    "- identify behavioural syllables with keypoint moseq 2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f877740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q numpy pandas opencv-python\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a803352",
   "metadata": {},
   "source": [
    "create a csv to video dictionary with the mice and trials we are interested in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038e8e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/\"\n",
    "\n",
    "#this is where the csv files of interest are stored\n",
    "csvs = []\n",
    "\n",
    "#this is where we store the videos\n",
    "videos = []\n",
    "\n",
    "\n",
    "for i in os.listdir(main_dir):\n",
    "    if \"6357\" in i or \"6359\" in i:\n",
    "        mouse_dir = os.path.join(main_dir, i)\n",
    "        # print(mouse_dir[-10:])\n",
    "        for session in os.listdir(mouse_dir):\n",
    "            if 'habituation' in session or '1.1' in session or \"3.5\" in session or \"3.6\" in session or \"3.7\" in session or \"3.8\" in session:\n",
    "                session_dir = os.path.join(mouse_dir, session)\n",
    "                # print(f\"    -{session_dir[-10:]}\")\n",
    "\n",
    "                for file in os.listdir(session_dir):\n",
    "\n",
    "                    full_path_file = os.path.join(session_dir, file)\n",
    "\n",
    "                    if \"trial_info.csv\" in file and \"clean\" not in file:\n",
    "                        csvs.append(full_path_file)\n",
    "                        # print(f\"        -{file}\")\n",
    "                    elif \"mp4\" in file:\n",
    "                        videos.append(full_path_file)\n",
    "\n",
    "csv_video = dict(zip(csvs, videos))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c145ad",
   "metadata": {},
   "source": [
    "in this notebook we will select the rois in the first frame of the first video, and they will become the reference rois. We then use homography to adapt the rois to the other videos, and have the option of accepting/redrawing/skipping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa46c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS to where you want the reference ROI CSV saved ===\n",
    "REF_ROIS_CSV = main_dir + \"rois_reference.csv\" # <- put your desired path here\n",
    "\n",
    "# the ordered ROI names you’ll draw on the first (reference) video\n",
    "ROI_NAMES = [\"entrance1\", \"entrance2\"] + [f\"roi{i}\" for i in range(1, 5)]\n",
    "\n",
    "# homography scale for feature matching (smaller = faster; 0.5–0.8 is a good range)\n",
    "PYR_SCALE = 0.75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aad0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_video_any(path: str):\n",
    "    for backend in (cv.CAP_MSMF, cv.CAP_FFMPEG, cv.CAP_DSHOW, cv.CAP_ANY):\n",
    "        cap = cv.VideoCapture(path, backend)\n",
    "        ok, frame = cap.read()\n",
    "        if ok and frame is not None:\n",
    "            cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "            return cap\n",
    "        try: cap.release()\n",
    "        except Exception: pass\n",
    "    return None\n",
    "\n",
    "def grab_first_frame(video_path: str) -> Optional[np.ndarray]:\n",
    "    cap = open_video_any(video_path)\n",
    "    if cap is None:\n",
    "        return None\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    return frame if ok else None\n",
    "\n",
    "def save_rois_csv(dest_csv: Path, rows: List[Tuple[str,int,int,int,int]]) -> None:\n",
    "    df = pd.DataFrame(rows, columns=[\"name\",\"x\",\"y\",\"w\",\"h\"])\n",
    "    dest_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(dest_csv, index=False)\n",
    "\n",
    "def load_rois_long(csv_path: str) -> List[Tuple[str,int,int,int,int]]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    need = {\"name\",\"x\",\"y\",\"w\",\"h\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        raise ValueError(f\"ROI CSV must have columns {need}; got {set(df.columns)}\")\n",
    "    out = []\n",
    "    for name, x, y, w, h in df[[\"name\",\"x\",\"y\",\"w\",\"h\"]].itertuples(index=False, name=None):\n",
    "        out.append((str(name).lower(), int(x), int(y), int(w), int(h)))\n",
    "    return out\n",
    "\n",
    "def overlay_rois(image: np.ndarray, rows: List[Tuple[str,int,int,int,int]], color=(0,255,0)) -> np.ndarray:\n",
    "    out = image.copy()\n",
    "    for name, x, y, w, h in rows:\n",
    "        cv.rectangle(out, (x, y), (x+w, y+h), color, 2)\n",
    "        cv.putText(out, name, (x, max(20, y-10)), cv.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv.LINE_AA)\n",
    "    return out\n",
    "\n",
    "def draw_rois_on_first_frame(video_path: str, roi_names=ROI_NAMES, scale: float = 2.0\n",
    "                             ) -> List[Tuple[str,int,int,int,int]]:\n",
    "    \"\"\"\n",
    "    Interactively draw the ROIs in the order given by roi_names.\n",
    "    Returns [(name,x,y,w,h)] in original-resolution coordinates.\n",
    "    \"\"\"\n",
    "    frame = grab_first_frame(video_path)\n",
    "    if frame is None:\n",
    "        raise RuntimeError(f\"Could not open/read: {video_path}\")\n",
    "\n",
    "    disp = cv.resize(frame, None, fx=scale, fy=scale, interpolation=cv.INTER_LINEAR)\n",
    "    win = \"Draw ROIs - ENTER to confirm, ESC to skip\"\n",
    "    cv.namedWindow(win, cv.WINDOW_NORMAL)\n",
    "    cv.resizeWindow(win, disp.shape[1], disp.shape[0])\n",
    "    try:\n",
    "        cv.setWindowProperty(win, cv.WND_PROP_TOPMOST, 1)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    selections: List[Tuple[str,int,int,int,int]] = []\n",
    "    overlays: List[Tuple[str,int,int,int,int]] = []\n",
    "\n",
    "    for name in roi_names:\n",
    "        frame_show = disp.copy()\n",
    "        for nm, sx, sy, sw, sh in overlays:\n",
    "            cv.rectangle(frame_show, (sx, sy), (sx+sw, sy+sh), (255,0,0), 2)\n",
    "            cv.putText(frame_show, nm, (sx, max(20, sy-10)), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,0), 2, cv.LINE_AA)\n",
    "        cv.putText(frame_show, f\"Draw {name} then ENTER (ESC to skip)\", (20, 40),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3, cv.LINE_AA)\n",
    "\n",
    "        r = cv.selectROI(win, frame_show, fromCenter=False, showCrosshair=True)\n",
    "        if r == (0,0,0,0):\n",
    "            print(f\"[WARN] Skipped ROI: {name}\")\n",
    "            continue\n",
    "        x = int(r[0] / scale); y = int(r[1] / scale)\n",
    "        w = int(r[2] / scale); h = int(r[3] / scale)\n",
    "        selections.append((name.lower(), x, y, w, h))\n",
    "        overlays.append((name, r[0], r[1], r[2], r[3]))\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    if not selections:\n",
    "        raise RuntimeError(\"No ROIs were drawn.\")\n",
    "    return selections\n",
    "\n",
    "# --- homography (ORB + BFMatcher + RANSAC) ---\n",
    "def detect_homography(ref_img: np.ndarray, cur_img: np.ndarray) -> Optional[np.ndarray]:\n",
    "    g1 = cv.cvtColor(ref_img, cv.COLOR_BGR2GRAY) if ref_img.ndim == 3 else ref_img\n",
    "    g2 = cv.cvtColor(cur_img, cv.COLOR_BGR2GRAY) if cur_img.ndim == 3 else cur_img\n",
    "    orb = cv.ORB_create(nfeatures=5000, scaleFactor=1.2, edgeThreshold=15, patchSize=31)\n",
    "    k1, d1 = orb.detectAndCompute(g1, None)\n",
    "    k2, d2 = orb.detectAndCompute(g2, None)\n",
    "    if d1 is None or d2 is None or len(k1) < 20 or len(k2) < 20:\n",
    "        return None\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(d1, d2)\n",
    "    if len(matches) < 20:\n",
    "        return None\n",
    "    matches = sorted(matches, key=lambda m: m.distance)[:500]\n",
    "    src = np.float32([k1[m.queryIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "    dst = np.float32([k2[m.trainIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "    H, mask = cv.findHomography(src, dst, cv.RANSAC, 3.0)\n",
    "    if H is None: return None\n",
    "    if mask is not None and int(mask.sum()) < 20:\n",
    "        return None\n",
    "    return H\n",
    "\n",
    "def project_rect(x: int, y: int, w: int, h: int, H: np.ndarray) -> Tuple[int,int,int,int]:\n",
    "    pts = np.array([[x,y], [x+w,y], [x+w,y+h], [x,y+h]], dtype=np.float32).reshape(-1,1,2)\n",
    "    proj = cv.perspectiveTransform(pts, H).reshape(-1,2)\n",
    "    xs, ys = proj[:,0], proj[:,1]\n",
    "    x0 = max(0, int(np.floor(xs.min()))); y0 = max(0, int(np.floor(ys.min())))\n",
    "    x1 = int(np.ceil(xs.max())); y1 = int(np.ceil(ys.max()))\n",
    "    return x0, y0, max(1, x1-x0), max(1, y1-y0)\n",
    "\n",
    "def auto_rois_from_reference(cur_img: np.ndarray,\n",
    "                             ref_img: np.ndarray,\n",
    "                             ref_rows: List[Tuple[str,int,int,int,int]],\n",
    "                             pyr_scale: float = 0.75) -> Optional[List[Tuple[str,int,int,int,int]]]:\n",
    "    \"\"\"\n",
    "    Estimate homography (optionally on downscaled images) and map ref ROIs -> current frame.\n",
    "    \"\"\"\n",
    "    if pyr_scale != 1.0:\n",
    "        def S(a): return np.array([[a,0,0],[0,a,0],[0,0,1]], dtype=np.float32)\n",
    "        ref_s = cv.resize(ref_img, None, fx=pyr_scale, fy=pyr_scale)\n",
    "        cur_s = cv.resize(cur_img, None, fx=pyr_scale, fy=pyr_scale)\n",
    "        Hs = detect_homography(ref_s, cur_s)\n",
    "        if Hs is None: return None\n",
    "        H = np.linalg.inv(S(pyr_scale)) @ Hs @ S(pyr_scale)\n",
    "    else:\n",
    "        H = detect_homography(ref_img, cur_img)\n",
    "        if H is None: return None\n",
    "\n",
    "    out = []\n",
    "    for name, x, y, w, h in ref_rows:\n",
    "        x2, y2, w2, h2 = project_rect(x, y, w, h, H)\n",
    "        out.append((name, x2, y2, w2, h2))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4ee029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pairs: 10\n"
     ]
    }
   ],
   "source": [
    "# Your code that builds csv_video should already have run.\n",
    "# csv_video maps: trial_csv_path -> video_path\n",
    "assert isinstance(csv_video, dict) and len(csv_video) > 0, \"csv_video is empty\"\n",
    "print(\"Found pairs:\", len(csv_video))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6243addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference video: C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6357\\2024-08-27_13_05_196357session3.5\\6357_2024-08-27_13_05_19s3.5.mp4\n",
      "Saved reference ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/rois_reference.csv\n"
     ]
    }
   ],
   "source": [
    "# pick the first (CSV -> VIDEO) pair from your dict\n",
    "first_csv, first_video = next(iter(csv_video.items()))\n",
    "print(\"Reference video:\", first_video)\n",
    "\n",
    "# draw interactively on the first video\n",
    "ref_rows = draw_rois_on_first_frame(first_video, roi_names=ROI_NAMES, scale=2.0)\n",
    "save_rois_csv(Path(REF_ROIS_CSV), ref_rows)\n",
    "print(\"Saved reference ROIs ->\", REF_ROIS_CSV)\n",
    "\n",
    "# (optional) quick visual check\n",
    "frame0 = grab_first_frame(first_video)\n",
    "vis0 = overlay_rois(frame0, ref_rows)\n",
    "cv.imshow(\"Reference ROIs (press any key to close)\", vis0); cv.waitKey(0); cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f76366",
   "metadata": {},
   "source": [
    "This iterates over all the other videos in csv_video, adapts the ROIs via homography, shows you a quick preview `(Y=accept, R=redraw, Q=skip)`, and saves a per-video ROI file named \"<video_stem>_rois.csv\" next to each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc13ac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6357/2024-08-28_11_58_146357session3.6/6357_2024-08-28_11_58_14s3.6_rois.csv  (accepted_adapted)\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6357/2024-08-29_10_23_026357session3.7/6357_2024-08-29_10_23_02s3.7_rois.csv  (accepted_adapted)\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6357/2024-08-30_10_07_556357session3.8/6357_2024-08-30_10_07_55s3.8_rois.csv  (accepted_adapted)\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6357/habituation/6357_2024-08-15_11_23_10_rois.csv  (accepted_adapted)\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6359/2024-08-27_14_08_356359session3.5/6359_2024-08-27_14_08_35s3.5_rois.csv  (accepted_adapted)\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6359/2024-08-28_13_28_276359session3.6/6359_2024-08-28_13_28_27s3.6_rois.csv  (accepted_adapted)\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6359/2024-08-29_11_39_286359session3.7/6359_2024-08-29_11_39_28s3.7_rois.csv  (accepted_adapted)\n",
      "Manual redraw...\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6359/2024-08-30_11_28_106359session3.8/6359_2024-08-30_11_28_10s3.8_rois.csv  (redrawn_manual)\n",
      "Saved ROIs -> C:/Users/shahd/Box/Awake Project/Maze data/simplermaze/mouse 6359/habituation/6359_2024-08-15_14_05_08_rois.csv  (accepted_adapted)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>roi_csv</th>\n",
       "      <th>how</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>accepted_adapted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>accepted_adapted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>accepted_adapted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>accepted_adapted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>accepted_adapted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>accepted_adapted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>accepted_adapted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>redrawn_manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...</td>\n",
       "      <td>C:/Users/shahd/Box/Awake Project/Maze data/sim...</td>\n",
       "      <td>accepted_adapted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               video  \\\n",
       "0  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "1  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "2  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "3  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "4  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "5  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "6  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "7  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "8  C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\sim...   \n",
       "\n",
       "                                             roi_csv               how  \n",
       "0  C:/Users/shahd/Box/Awake Project/Maze data/sim...  accepted_adapted  \n",
       "1  C:/Users/shahd/Box/Awake Project/Maze data/sim...  accepted_adapted  \n",
       "2  C:/Users/shahd/Box/Awake Project/Maze data/sim...  accepted_adapted  \n",
       "3  C:/Users/shahd/Box/Awake Project/Maze data/sim...  accepted_adapted  \n",
       "4  C:/Users/shahd/Box/Awake Project/Maze data/sim...  accepted_adapted  \n",
       "5  C:/Users/shahd/Box/Awake Project/Maze data/sim...  accepted_adapted  \n",
       "6  C:/Users/shahd/Box/Awake Project/Maze data/sim...  accepted_adapted  \n",
       "7  C:/Users/shahd/Box/Awake Project/Maze data/sim...    redrawn_manual  \n",
       "8  C:/Users/shahd/Box/Awake Project/Maze data/sim...  accepted_adapted  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_frame = grab_first_frame(first_video)\n",
    "ref_rows  = load_rois_long(REF_ROIS_CSV)\n",
    "\n",
    "adapted_summary = []\n",
    "\n",
    "for trials_csv, video in csv_video.items():\n",
    "    if video == first_video:\n",
    "        # skip the reference; it's already drawn and saved\n",
    "        continue\n",
    "\n",
    "    vp = Path(video).resolve()\n",
    "    out_csv = vp.with_suffix(\"\").as_posix() + \"_rois.csv\"\n",
    "\n",
    "    cur_frame = grab_first_frame(str(vp))\n",
    "    if cur_frame is None:\n",
    "        print(f\"[SKIP] Cannot open video: {vp}\")\n",
    "        continue\n",
    "\n",
    "    # try homography-based transfer\n",
    "    adapted = auto_rois_from_reference(cur_frame, ref_frame, ref_rows, pyr_scale=PYR_SCALE)\n",
    "\n",
    "    # preview: Y=accept, R=manual redraw, Q=skip\n",
    "    if adapted is not None:\n",
    "        preview = overlay_rois(cur_frame, adapted, color=(0,255,0))\n",
    "    else:\n",
    "        preview = overlay_rois(cur_frame, ref_rows, color=(0,255,255))  # fallback preview\n",
    "\n",
    "    win = f\"Adapted ROIs: {vp.name}  [Y=accept | R=redraw | Q=skip]\"\n",
    "    cv.namedWindow(win, cv.WINDOW_NORMAL)\n",
    "    cv.imshow(win, preview)\n",
    "    key = cv.waitKey(0) & 0xFF\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    if key in (ord('y'), ord('Y')) and adapted is not None:\n",
    "        rows = adapted\n",
    "        reason = \"accepted_adapted\"\n",
    "    elif key in (ord('r'), ord('R')):\n",
    "        print(\"Manual redraw...\")\n",
    "        rows = draw_rois_on_first_frame(str(vp), roi_names=[n for n, *_ in ref_rows], scale=2.0)\n",
    "        reason = \"redrawn_manual\"\n",
    "    elif key in (ord('q'), ord('Q')):\n",
    "        print(f\"[SKIP] user skipped: {vp.name}\")\n",
    "        continue\n",
    "    else:\n",
    "        # default fallback: if adaptation failed and not redrawn, use reference ROIs\n",
    "        rows = adapted if adapted is not None else ref_rows\n",
    "        reason = \"fallback_to_reference\" if adapted is None else \"accepted_adapted_default\"\n",
    "\n",
    "    save_rois_csv(Path(out_csv), rows)\n",
    "    print(f\"Saved ROIs -> {out_csv}  ({reason})\")\n",
    "    adapted_summary.append({\"video\": str(vp), \"roi_csv\": out_csv, \"how\": reason})\n",
    "\n",
    "pd.DataFrame(adapted_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "562b46f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Using ffmpeg at: c:\\Users\\shahd\\OneDrive\\Documents\\GitHub\\mice-maze\\.venv\\lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win-x86_64-v7.1.exe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['c:\\\\Users\\\\shahd\\\\OneDrive\\\\Documents\\\\GitHub\\\\mice-maze\\\\.venv\\\\lib\\\\site-packages\\\\imageio_ffmpeg\\\\binaries\\\\ffmpeg-win-x86_64-v7.1.exe', '-version'], returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install & point to a working ffmpeg binary for THIS kernel\n",
    "%pip install -q imageio-ffmpeg\n",
    "\n",
    "import os, imageio_ffmpeg, shutil, subprocess\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "print(\"Using ffmpeg at:\", os.environ[\"IMAGEIO_FFMPEG_EXE\"])\n",
    "\n",
    "# sanity check\n",
    "subprocess.run([os.environ[\"IMAGEIO_FFMPEG_EXE\"], \"-version\"], check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d120cbba",
   "metadata": {},
   "source": [
    "This script relies on the rois.csv for every video to segment the trials based on the same logic of simplermaze (left e2 after e1 == entered maze == trial starts; ledt e1 after e2 == left maze == trial ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f802622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, subprocess\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "\n",
    "# ---------- ffmpeg ----------\n",
    "def ffmpeg_bin():\n",
    "    return os.environ.get(\"IMAGEIO_FFMPEG_EXE\") or \"ffmpeg\"\n",
    "\n",
    "def ensure_ffmpeg():\n",
    "    exe = ffmpeg_bin()\n",
    "    ok = (Path(exe).exists() if (\":\" in exe or exe.endswith(\".exe\")) else shutil.which(exe) is not None)\n",
    "    if not ok:\n",
    "        raise RuntimeError(f\"ffmpeg not found at '{exe}'. Install ffmpeg or set IMAGEIO_FFMPEG_EXE.\")\n",
    "\n",
    "# ---------- small utils ----------\n",
    "def _grab(frame, r):\n",
    "    return frame[r[\"ystart\"]:r[\"ystart\"]+r[\"ylen\"], r[\"xstart\"]:r[\"xstart\"]+r[\"xlen\"]]\n",
    "\n",
    "def compute_roi_baselines(cap, rois: Dict[str,Dict[str,int]], num_frames=10, thresh_value=160):\n",
    "    thresholds = {k: 0.0 for k in rois}; n = 0\n",
    "    pos = int(cap.get(cv.CAP_PROP_POS_FRAMES))\n",
    "    for _ in range(num_frames):\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) if frame.ndim == 3 else frame\n",
    "        _, bw = cv.threshold(gray, thresh_value, 255, cv.THRESH_BINARY)\n",
    "        for name, rect in rois.items():\n",
    "            thresholds[name] += float(np.sum(_grab(bw, rect)))\n",
    "        n += 1\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, pos)\n",
    "    if n == 0:\n",
    "        raise RuntimeError(\"Could not read frames to compute baselines.\")\n",
    "    for k in thresholds: thresholds[k] /= n\n",
    "    return thresholds\n",
    "\n",
    "def detect_bouts_by_entrances(\n",
    "    video_path: str,\n",
    "    rois_csv: str,\n",
    "    thresh_value: int = 160,\n",
    "    threshold_factor: float = 0.5,\n",
    "    min_duration_s: float = 0.4,\n",
    "    merge_gap_s: float = 0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build bouts using entrance logic:\n",
    "      - leave entrance1 then leave entrance2  => ENTER\n",
    "      - leave entrance2 then leave entrance1  => EXIT\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(rois_csv)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    rois = {str(n).lower(): {\"xstart\":int(x), \"ystart\":int(y), \"xlen\":int(w), \"ylen\":int(h)}\n",
    "            for n,x,y,w,h in df[[\"name\",\"x\",\"y\",\"w\",\"h\"]].itertuples(index=False, name=None)}\n",
    "    if \"entrance1\" not in rois or \"entrance2\" not in rois:\n",
    "        raise ValueError(\"ROIs must include 'entrance1' and 'entrance2'.\")\n",
    "\n",
    "    # open video\n",
    "    for backend in (cv.CAP_MSMF, cv.CAP_FFMPEG, cv.CAP_DSHOW, cv.CAP_ANY):\n",
    "        cap = cv.VideoCapture(str(video_path), backend)\n",
    "        ok, _ = cap.read()\n",
    "        if ok: \n",
    "            cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "            break\n",
    "        try: cap.release()\n",
    "        except: pass\n",
    "        cap = None\n",
    "    if cap is None:\n",
    "        raise FileNotFoundError(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    fps = cap.get(cv.CAP_PROP_FPS) or 0.0\n",
    "    if fps <= 1e-3: fps = 30.0\n",
    "    total_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT)) or None\n",
    "\n",
    "    baselines = compute_roi_baselines(cap, rois, num_frames=10, thresh_value=thresh_value)\n",
    "    def occupied(bw, name):\n",
    "        return (np.sum(_grab(bw, rois[name])) < baselines[name] * threshold_factor)\n",
    "\n",
    "    ent1_prev = False; ent2_prev = False\n",
    "    hasLeft1 = False; hasLeft2 = False\n",
    "    entered = False\n",
    "    bouts = []\n",
    "    cur_start = None\n",
    "\n",
    "    frame_idx = 0\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) if frame.ndim == 3 else frame\n",
    "        _, bw = cv.threshold(gray, thresh_value, 255, cv.THRESH_BINARY)\n",
    "\n",
    "        e1_now = occupied(bw, \"entrance1\")\n",
    "        e2_now = occupied(bw, \"entrance2\")\n",
    "\n",
    "        left1 = (not e1_now) and ent1_prev\n",
    "        left2 = (not e2_now) and ent2_prev\n",
    "\n",
    "        if left1:\n",
    "            hasLeft1 = True\n",
    "            if hasLeft2 and entered:\n",
    "                # EXIT (sequence 2->1)\n",
    "                end_s = frame_idx / fps\n",
    "                if cur_start is not None:\n",
    "                    bouts.append((cur_start, end_s))\n",
    "                cur_start = None\n",
    "                entered = False\n",
    "                hasLeft1 = hasLeft2 = False\n",
    "\n",
    "        if left2:\n",
    "            hasLeft2 = True\n",
    "            if hasLeft1 and not entered:\n",
    "                # ENTER (sequence 1->2)\n",
    "                cur_start = frame_idx / fps\n",
    "                entered = True\n",
    "\n",
    "        ent1_prev, ent2_prev = e1_now, e2_now\n",
    "        frame_idx += 1\n",
    "\n",
    "    if entered and cur_start is not None:\n",
    "        end_s = (total_frames / fps) if total_frames else (frame_idx / fps)\n",
    "        bouts.append((cur_start, end_s))\n",
    "    cap.release()\n",
    "\n",
    "    # merge short gaps & drop tiny bouts\n",
    "    if not bouts:\n",
    "        return []\n",
    "    merged = []\n",
    "    s0, e0 = bouts[0]\n",
    "    for s, e in bouts[1:]:\n",
    "        if s - e0 <= merge_gap_s:\n",
    "            e0 = e\n",
    "        else:\n",
    "            merged.append((s0, e0)); s0, e0 = s, e\n",
    "    merged.append((s0, e0))\n",
    "    return [(s, e) for (s, e) in merged if (e - s) >= min_duration_s]\n",
    "\n",
    "def cut_segment_ffmpeg(video, start_s, end_s, out_path, reencode=True):\n",
    "    ensure_ffmpeg()\n",
    "    out_path = Path(out_path); out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if reencode:\n",
    "        cmd = [\n",
    "            ffmpeg_bin(), \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "            \"-ss\", f\"{start_s:.3f}\", \"-t\", f\"{max(0.0, end_s - start_s):.3f}\",\n",
    "            \"-i\", str(video),\n",
    "            \"-map\", \"0:v:0?\", \"-c:v\", \"libx264\", \"-preset\", \"veryfast\", \"-crf\", \"18\",\n",
    "            \"-movflags\", \"+faststart\", \"-reset_timestamps\", \"1\", str(out_path)\n",
    "        ]\n",
    "    else:\n",
    "        cmd = [\n",
    "            ffmpeg_bin(), \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "            \"-ss\", f\"{start_s:.3f}\", \"-to\", f\"{end_s:.3f}\",\n",
    "            \"-i\", str(video),\n",
    "            \"-map\", \"0:v:0?\", \"-c\", \"copy\",\n",
    "            \"-movflags\", \"+faststart\", \"-reset_timestamps\", \"1\", str(out_path)\n",
    "        ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "def segment_video_by_detected_bouts(\n",
    "    video_path: str,\n",
    "    rois_csv: str,\n",
    "    outdir: str,\n",
    "    base_label: str,\n",
    "    padding_s: float,\n",
    "    reencode: bool,\n",
    "    thresh_value: int,\n",
    "    threshold_factor: float,\n",
    "    min_duration_s: float,\n",
    "    merge_gap_s: float,\n",
    "):\n",
    "    bouts = detect_bouts_by_entrances(\n",
    "        video_path, rois_csv,\n",
    "        thresh_value=thresh_value,\n",
    "        threshold_factor=threshold_factor,\n",
    "        min_duration_s=min_duration_s,\n",
    "        merge_gap_s=merge_gap_s,\n",
    "    )\n",
    "    segments = []\n",
    "    for i, (s, e) in enumerate(bouts):\n",
    "        s2 = max(0.0, s - padding_s)\n",
    "        e2 = max(s2, e + padding_s)\n",
    "        out_name = f\"{base_label}_trial_{i:03d}.mp4\"\n",
    "        out_path = Path(outdir) / out_name\n",
    "        cut_segment_ffmpeg(video_path, s2, e2, out_path, reencode=reencode)\n",
    "        segments.append({\"trial_index\": i, \"start_s\": s, \"end_s\": e, \"path\": str(out_path)})\n",
    "    return segments\n",
    "\n",
    "def update_trials_csv_with_paths(trials_csv: str, segments, column_name=\"video_segment_path\", inplace=False):\n",
    "    trials_csv = Path(trials_csv).resolve()\n",
    "    df = pd.read_csv(trials_csv)\n",
    "    paths = [seg[\"path\"] for seg in segments]\n",
    "    n = min(len(df), len(paths))\n",
    "    if column_name not in df.columns:\n",
    "        df[column_name] = pd.NA\n",
    "    df.loc[:n-1, column_name] = paths[:n]\n",
    "    updated = trials_csv if inplace else trials_csv.with_name(trials_csv.stem + \"_with_segments_detected.csv\")\n",
    "    df.to_csv(updated, index=False)\n",
    "    return str(updated), n, len(paths), len(df)\n",
    "\n",
    "def build_outdir(video_path: Path):\n",
    "    # put per-video segments under: <video_dir>/segments_detected/<video_stem>/\n",
    "    return video_path.parent / \"segments_detected\" / video_path.stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a1980a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# 1) Override the output folder to the legacy \"segments\" (next to the video)\n",
    "def build_outdir(video_path: Path) -> Path:\n",
    "    return video_path.parent / \"segments\"\n",
    "\n",
    "# 2) Helper: remove ONLY old trial clips for this video (keeps other files intact)\n",
    "def purge_old_segments_for_video(video_path: Path, dry_run=False) -> int:\n",
    "    outdir = build_outdir(video_path)\n",
    "    if not outdir.exists():\n",
    "        return 0\n",
    "    pattern = f\"{video_path.stem}_trial_*.mp4\"\n",
    "    to_delete = list(outdir.glob(pattern))\n",
    "    if dry_run:\n",
    "        print(f\"[dry-run] would delete {len(to_delete)} in {outdir} (pattern {pattern})\")\n",
    "        for p in to_delete[:5]:\n",
    "            print(\" \", p.name)\n",
    "        return len(to_delete)\n",
    "    # delete\n",
    "    for p in to_delete:\n",
    "        try:\n",
    "            p.unlink()\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] could not delete {p.name}: {e}\")\n",
    "    return len(to_delete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61cd4557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Fast first-frame helpers (define once per kernel)\n",
    "\n",
    "# If you don't already have it in THIS kernel:\n",
    "%pip install -q imageio-ffmpeg\n",
    "\n",
    "import os, subprocess\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "import imageio_ffmpeg\n",
    "\n",
    "# Prefer a known-good ffmpeg binary (bundled by imageio-ffmpeg)\n",
    "os.environ.setdefault(\"IMAGEIO_FFMPEG_EXE\", imageio_ffmpeg.get_ffmpeg_exe())\n",
    "\n",
    "def ffmpeg_bin():\n",
    "    \"\"\"Return the ffmpeg executable path (env var if set, else 'ffmpeg').\"\"\"\n",
    "    return os.environ.get(\"IMAGEIO_FFMPEG_EXE\") or \"ffmpeg\"\n",
    "\n",
    "def open_video_fast(path: str):\n",
    "    \"\"\"Try FFmpeg first (usually fastest), then other OpenCV backends.\"\"\"\n",
    "    for backend in (cv.CAP_FFMPEG, cv.CAP_MSMF, cv.CAP_DSHOW, cv.CAP_ANY):\n",
    "        cap = cv.VideoCapture(path, backend)\n",
    "        ok, frame = cap.read()\n",
    "        if ok and frame is not None:\n",
    "            cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "            return cap\n",
    "        try: cap.release()\n",
    "        except Exception: pass\n",
    "    return None\n",
    "\n",
    "def grab_first_frame_fast(video_path: str):\n",
    "    \"\"\"Open with a fast backend and grab frame 0 (OpenCV only).\"\"\"\n",
    "    cap = open_video_fast(video_path)\n",
    "    if cap is None:\n",
    "        return None\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    return frame if ok else None\n",
    "\n",
    "def grab_first_frame_ffmpeg(video_path: str):\n",
    "    \"\"\"\n",
    "    Snapshot the first frame via ffmpeg to a temp JPEG, read with OpenCV,\n",
    "    then clean up. Falls back to grab_first_frame_fast on error.\n",
    "    \"\"\"\n",
    "    exe = ffmpeg_bin()\n",
    "    tmp = Path(video_path).with_suffix(\".firstframe.jpg\")\n",
    "    try:\n",
    "        cmd = [\n",
    "            exe, \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "            \"-nostdin\", \"-y\",\n",
    "            \"-ss\", \"0\", \"-i\", video_path,\n",
    "            \"-frames:v\", \"1\", str(tmp)\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True)\n",
    "        frame = cv.imread(str(tmp), cv.IMREAD_COLOR)\n",
    "        try:\n",
    "            tmp.unlink()  # delete the temp file\n",
    "        except Exception:\n",
    "            pass\n",
    "        return frame\n",
    "    except Exception:\n",
    "        return grab_first_frame_fast(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4d44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[roi] using 6357_2024-08-27_13_05_19s3.5_rois.csv\n",
      "[clean] removed 55 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\2024-08-27_13_05_196357session3.5\\segments\n",
      "[csv] mouse6357_session3.5_trial_info.csv: filled 54/57 rows -> mouse6357_session3.5_trial_info.csv\n",
      "[roi] using 6357_2024-08-28_11_58_14s3.6_rois.csv\n",
      "[clean] removed 55 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\2024-08-28_11_58_146357session3.6\\segments\n",
      "[csv] mouse6357_session3.6_trial_info.csv: filled 67/67 rows -> mouse6357_session3.6_trial_info.csv\n",
      "[roi] using 6357_2024-08-29_10_23_02s3.7_rois.csv\n",
      "[clean] removed 66 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\2024-08-29_10_23_026357session3.7\\segments\n",
      "[csv] mouse6357_session3.7_trial_info.csv: filled 62/69 rows -> mouse6357_session3.7_trial_info.csv\n",
      "[roi] using 6357_2024-08-30_10_07_55s3.8_rois.csv\n",
      "[clean] removed 57 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\2024-08-30_10_07_556357session3.8\\segments\n",
      "[csv] mouse6357_session3.8_trial_info.csv: filled 57/73 rows -> mouse6357_session3.8_trial_info.csv\n",
      "[roi] using 6357_2024-08-15_11_23_10_rois.csv\n",
      "[clean] removed 37 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6357\\habituation\\segments\n",
      "[csv] mouse6357_session1.1_trial_info.csv: filled 50/50 rows -> mouse6357_session1.1_trial_info.csv\n",
      "[roi] using 6359_2024-08-27_14_08_35s3.5_rois.csv\n",
      "[clean] removed 52 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6359\\2024-08-27_14_08_356359session3.5\\segments\n",
      "[csv] mouse6359_session3.5_trial_info.csv: filled 55/64 rows -> mouse6359_session3.5_trial_info.csv\n",
      "[roi] using 6359_2024-08-28_13_28_27s3.6_rois.csv\n",
      "[clean] removed 73 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6359\\2024-08-28_13_28_276359session3.6\\segments\n",
      "[csv] mouse6359_session3.6_trial_info.csv: filled 72/96 rows -> mouse6359_session3.6_trial_info.csv\n",
      "[roi] using 6359_2024-08-29_11_39_28s3.7_rois.csv\n",
      "[clean] removed 61 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6359\\2024-08-29_11_39_286359session3.7\\segments\n",
      "[csv] mouse6359_session3.7_trial_info.csv: filled 64/69 rows -> mouse6359_session3.7_trial_info.csv\n",
      "[roi] using 6359_2024-08-30_11_28_10s3.8_rois.csv\n",
      "[clean] removed 57 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6359\\2024-08-30_11_28_106359session3.8\\segments\n",
      "[csv] mouse6359_session3.8_trial_info.csv: filled 60/71 rows -> mouse6359_session3.8_trial_info.csv\n",
      "[roi] using 6359_2024-08-15_14_05_08_rois.csv\n",
      "[clean] removed 40 old segments in C:\\Users\\shahd\\Box\\Awake Project\\Maze data\\simplermaze\\mouse 6359\\habituation\\segments\n",
      "[csv] mouse6359_session1.1_trial_info.csv: filled 40/41 rows -> mouse6359_session1.1_trial_info.csv\n",
      "\n",
      "DONE. Replaced segments for: 10 sessions\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# If you skipped the progress/timing wrappers earlier, this will still work.\n",
    "# Make sure ffmpeg is available (IMAGEIO_FFMPEG_EXE set, or ffmpeg on PATH).\n",
    "\n",
    "summaries = []\n",
    "ref_rows = load_rois_long(REF_ROIS_CSV)  # from your earlier draw cell\n",
    "\n",
    "for trials_csv, video in csv_video.items():\n",
    "    vp = Path(video).resolve()\n",
    "    tp = Path(trials_csv).resolve()\n",
    "    if not vp.exists():\n",
    "        print(f\"[SKIP] Video not found: {vp}\"); continue\n",
    "    if not tp.exists():\n",
    "        print(f\"[SKIP] CSV not found: {tp}\"); continue\n",
    "\n",
    "    # per-video ROI file (created earlier by your adapt step; if missing, we try quick adapt/fallback)\n",
    "    rois_csv = vp.with_suffix(\"\").as_posix() + \"_rois.csv\"\n",
    "    if not Path(rois_csv).exists():\n",
    "        # QUICK auto-adapt (no GUI); fallback to reference ROIs if needed\n",
    "        cur_frame = grab_first_frame_ffmpeg(str(vp)) or grab_first_frame_fast(str(vp))\n",
    "        if cur_frame is None:\n",
    "            print(f\"[SKIP] Cannot open video for ROI: {vp}\"); continue\n",
    "        ref_frame = grab_first_frame_ffmpeg(first_video) or grab_first_frame_fast(first_video)\n",
    "        adapted = auto_rois_from_reference(cur_frame, ref_frame, ref_rows, pyr_scale=PYR_SCALE)\n",
    "        rows = adapted if adapted is not None else ref_rows\n",
    "        save_rois_csv(Path(rois_csv), rows)\n",
    "        print(f\"[roi] {'adapted' if adapted is not None else 'fallback ref'} -> {Path(rois_csv).name}\")\n",
    "    else:\n",
    "        print(f\"[roi] using {Path(rois_csv).name}\")\n",
    "\n",
    "    # purge ONLY this video's old CSV-based clips in legacy segments/\n",
    "    deleted = purge_old_segments_for_video(vp, dry_run=False)\n",
    "    if deleted:\n",
    "        print(f\"[clean] removed {deleted} old segments in {build_outdir(vp)}\")\n",
    "\n",
    "    # cut NEW vision-logic segments into the SAME legacy folder\n",
    "    outdir = build_outdir(vp)\n",
    "    segs = segment_video_by_detected_bouts(\n",
    "        video_path=str(vp),\n",
    "        rois_csv=rois_csv,\n",
    "        outdir=str(outdir),\n",
    "        base_label=vp.stem,\n",
    "        padding_s=0.10,        # adjust if you want more/less context at boundaries\n",
    "        reencode=True,         # precise cuts; set False for speed (keyframe aligned)\n",
    "        thresh_value=160,\n",
    "        threshold_factor=0.50,\n",
    "        min_duration_s=0.40,\n",
    "        merge_gap_s=0.20,\n",
    "    )\n",
    "\n",
    "    # update the trial CSV to point at THESE new files in legacy segments/\n",
    "    updated_csv_path, filled, n_segments, n_rows = update_trials_csv_with_paths(\n",
    "        trials_csv=str(tp),\n",
    "        segments=segs,\n",
    "        column_name=\"video_segment_path\",\n",
    "        inplace=True,          # overwrite the original *_trial_info.csv mapping\n",
    "    )\n",
    "    print(f\"[csv] {Path(tp).name}: filled {filled}/{n_rows} rows -> {Path(updated_csv_path).name}\")\n",
    "\n",
    "    summaries.append({\n",
    "        \"video\": str(vp),\n",
    "        \"roi_csv\": rois_csv,\n",
    "        \"segments_outdir\": str(outdir),\n",
    "        \"segments_made\": len(segs),\n",
    "        \"csv_original\": str(tp),\n",
    "        \"csv_updated\": updated_csv_path,\n",
    "        \"rows_filled\": filled,\n",
    "        \"csv_rows\": n_rows\n",
    "    })\n",
    "\n",
    "print(\"\\nDONE. Replaced segments for:\", len(summaries), \"sessions\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
