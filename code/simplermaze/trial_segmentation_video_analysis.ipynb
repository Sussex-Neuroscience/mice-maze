{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76170361",
   "metadata": {},
   "source": [
    "# Trial segmentation script\n",
    "\n",
    "This notebook is intended for the breakdown, classification and analysis of the behavioural states shown in the video, starting frmo a trial segmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce349f8",
   "metadata": {},
   "source": [
    "- `trial segmentation` takes the output of simplerCode.py (video + .csv), and segments the video based on mouse entry and exit times in the video rather than the .csv\n",
    "- we then will manually sort the trials into `exploitative`, `explorative` and `nest`\n",
    "- extract speed and trajectories per trial\n",
    "- identify behavioural syllables with keypoint moseq 2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f877740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, install deps in THIS kernel\n",
    "%pip install -q numpy pandas opencv-python imageio-ffmpeg\n",
    "\n",
    "# Expose a working ffmpeg binary (uses imageio-ffmpeg's embedded build)\n",
    "import os, imageio_ffmpeg\n",
    "os.environ.setdefault(\"IMAGEIO_FFMPEG_EXE\", imageio_ffmpeg.get_ffmpeg_exe())\n",
    "print(\"Using ffmpeg:\", os.environ[\"IMAGEIO_FFMPEG_EXE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# === REQUIRED: point to a good reference video (same rig/pose) ===\n",
    "REFERENCE_VIDEO = r\"C:\\path\\to\\your\\best_reference_session.mp4\"  # <-- EDIT\n",
    "\n",
    "# Where to save the ROIs you draw on the reference\n",
    "REF_ROIS_CSV    = r\"C:\\path\\to\\rois_reference.csv\"               # <-- EDIT\n",
    "\n",
    "# Entrance + reward ROIs to draw (order matters)\n",
    "ROI_NAMES = [\"entrance1\", \"entrance2\"] + [f\"roi{i}\" for i in range(1, 5)]\n",
    "\n",
    "# Vision/segmentation params (tweak if needed)\n",
    "THRESH_VALUE     = 160    # binary threshold for occupancy\n",
    "THRESH_FACTOR    = 0.50   # ROI considered \"occupied\" if current white-sum < baseline*factor\n",
    "MIN_DURATION_S   = 0.40   # drop bouts shorter than this\n",
    "MERGE_GAP_S      = 0.20   # merge gaps shorter than this\n",
    "PADDING_S        = 0.10   # ± seconds added around each bout when cutting\n",
    "REENCODE         = True   # True=precise cuts; False=keyframe \"copy\"\n",
    "PYR_SCALE        = 0.75   # 0.5–0.8 often robust; 1.0 = full-res feature matching\n",
    "FALLBACK_TO_REF_ROIS = True  # if homography fails, use the reference ROIs directly\n",
    "\n",
    "# Output naming\n",
    "COLUMN_NAME = \"video_segment_path\"  # column added to *trial_info.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, subprocess\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "\n",
    "# ---------- ffmpeg ----------\n",
    "def ffmpeg_bin():\n",
    "    return os.environ.get(\"IMAGEIO_FFMPEG_EXE\") or \"ffmpeg\"\n",
    "\n",
    "def ensure_ffmpeg():\n",
    "    exe = ffmpeg_bin()\n",
    "    ok = (Path(exe).exists() if (\":\" in exe or exe.endswith(\".exe\")) else shutil.which(exe) is not None)\n",
    "    if not ok:\n",
    "        raise RuntimeError(f\"ffmpeg not found at '{exe}'. Install ffmpeg or set IMAGEIO_FFMPEG_EXE.\")\n",
    "\n",
    "# ---------- video helpers ----------\n",
    "def open_video_any(path: str):\n",
    "    for backend in (cv.CAP_MSMF, cv.CAP_FFMPEG, cv.CAP_DSHOW, cv.CAP_ANY):\n",
    "        cap = cv.VideoCapture(path, backend)\n",
    "        ok, frame = cap.read()\n",
    "        if ok and frame is not None:\n",
    "            cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "            return cap\n",
    "        try: cap.release()\n",
    "        except Exception: pass\n",
    "    return None\n",
    "\n",
    "def grab_first_frame(video_path: str) -> Optional[np.ndarray]:\n",
    "    cap = open_video_any(video_path)\n",
    "    if cap is None:\n",
    "        return None\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    return frame if ok else None\n",
    "\n",
    "# ---------- ROI utils ----------\n",
    "def save_rois_csv(dest_csv: Path, rows: List[Tuple[str,int,int,int,int]]) -> None:\n",
    "    df = pd.DataFrame(rows, columns=[\"name\",\"x\",\"y\",\"w\",\"h\"])\n",
    "    dest_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(dest_csv, index=False)\n",
    "\n",
    "def load_rois_long(csv_path: str) -> List[Tuple[str,int,int,int,int]]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    need = {\"name\",\"x\",\"y\",\"w\",\"h\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        raise ValueError(f\"ROI CSV must have columns {need}; got {set(df.columns)}\")\n",
    "    out = []\n",
    "    for name, x, y, w, h in df[[\"name\",\"x\",\"y\",\"w\",\"h\"]].itertuples(index=False, name=None):\n",
    "        out.append((str(name).lower(), int(x), int(y), int(w), int(h)))\n",
    "    return out\n",
    "\n",
    "def overlay_rois(image: np.ndarray, rows: List[Tuple[str,int,int,int,int]], color=(0,255,0)) -> np.ndarray:\n",
    "    out = image.copy()\n",
    "    for name, x, y, w, h in rows:\n",
    "        cv.rectangle(out, (x, y), (x+w, y+h), color, 2)\n",
    "        cv.putText(out, name, (x, max(20, y-10)), cv.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv.LINE_AA)\n",
    "    return out\n",
    "\n",
    "def draw_rois_on_first_frame(video_path: str, roi_names=ROI_NAMES, scale: float = 2.0\n",
    "                             ) -> List[Tuple[str,int,int,int,int]]:\n",
    "    frame = grab_first_frame(video_path)\n",
    "    if frame is None:\n",
    "        raise RuntimeError(f\"Could not open/read: {video_path}\")\n",
    "\n",
    "    disp = cv.resize(frame, None, fx=scale, fy=scale, interpolation=cv.INTER_LINEAR)\n",
    "    win = \"Draw ROIs - ENTER to confirm, ESC to skip\"\n",
    "    cv.namedWindow(win, cv.WINDOW_NORMAL)\n",
    "    cv.resizeWindow(win, disp.shape[1], disp.shape[0])\n",
    "    try:\n",
    "        cv.setWindowProperty(win, cv.WND_PROP_TOPMOST, 1)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    selections: List[Tuple[str,int,int,int,int]] = []\n",
    "    overlays: List[Tuple[str,int,int,int,int]] = []\n",
    "\n",
    "    for name in roi_names:\n",
    "        frame_show = disp.copy()\n",
    "        for nm, sx, sy, sw, sh in overlays:\n",
    "            cv.rectangle(frame_show, (sx, sy), (sx+sw, sy+sh), (255,0,0), 2)\n",
    "            cv.putText(frame_show, nm, (sx, max(20, sy-10)), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,0), 2, cv.LINE_AA)\n",
    "        cv.putText(frame_show, f\"Draw {name} then ENTER (ESC to skip)\", (20, 40),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3, cv.LINE_AA)\n",
    "\n",
    "        r = cv.selectROI(win, frame_show, fromCenter=False, showCrosshair=True)\n",
    "        if r == (0,0,0,0):\n",
    "            print(f\"[WARN] Skipped ROI: {name}\")\n",
    "            continue\n",
    "        x = int(r[0] / scale); y = int(r[1] / scale)\n",
    "        w = int(r[2] / scale); h = int(r[3] / scale)\n",
    "        selections.append((name.lower(), x, y, w, h))\n",
    "        overlays.append((name, r[0], r[1], r[2], r[3]))\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    if not selections:\n",
    "        raise RuntimeError(\"No ROIs were drawn.\")\n",
    "    return selections\n",
    "\n",
    "# ---------- Homography (ORB + BFMatcher + RANSAC) ----------\n",
    "def detect_homography(ref_img: np.ndarray, cur_img: np.ndarray) -> Optional[np.ndarray]:\n",
    "    g1 = cv.cvtColor(ref_img, cv.COLOR_BGR2GRAY) if ref_img.ndim == 3 else ref_img\n",
    "    g2 = cv.cvtColor(cur_img, cv.COLOR_BGR2GRAY) if cur_img.ndim == 3 else cur_img\n",
    "    orb = cv.ORB_create(nfeatures=5000, scaleFactor=1.2, edgeThreshold=15, patchSize=31)\n",
    "    k1, d1 = orb.detectAndCompute(g1, None)\n",
    "    k2, d2 = orb.detectAndCompute(g2, None)\n",
    "    if d1 is None or d2 is None or len(k1) < 20 or len(k2) < 20:\n",
    "        return None\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(d1, d2)\n",
    "    if len(matches) < 20:\n",
    "        return None\n",
    "    matches = sorted(matches, key=lambda m: m.distance)[:500]\n",
    "    src = np.float32([k1[m.queryIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "    dst = np.float32([k2[m.trainIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "    H, mask = cv.findHomography(src, dst, cv.RANSAC, 3.0)\n",
    "    if H is None: return None\n",
    "    if mask is not None and int(mask.sum()) < 20:\n",
    "        return None\n",
    "    return H\n",
    "\n",
    "def project_rect(x: int, y: int, w: int, h: int, H: np.ndarray) -> Tuple[int,int,int,int]:\n",
    "    pts = np.array([[x,y], [x+w,y], [x+w,y+h], [x,y+h]], dtype=np.float32).reshape(-1,1,2)\n",
    "    proj = cv.perspectiveTransform(pts, H).reshape(-1,2)\n",
    "    xs, ys = proj[:,0], proj[:,1]\n",
    "    x0 = max(0, int(np.floor(xs.min()))); y0 = max(0, int(np.floor(ys.min())))\n",
    "    x1 = int(np.ceil(xs.max())); y1 = int(np.ceil(ys.max()))\n",
    "    return x0, y0, max(1, x1-x0), max(1, y1-y0)\n",
    "\n",
    "def auto_rois_from_reference(cur_img: np.ndarray,\n",
    "                             ref_img: np.ndarray,\n",
    "                             ref_rows: List[Tuple[str,int,int,int,int]],\n",
    "                             pyr_scale: float = 0.75) -> Optional[List[Tuple[str,int,int,int,int]]]:\n",
    "    if pyr_scale != 1.0:\n",
    "        def S(a): return np.array([[a,0,0],[0,a,0],[0,0,1]], dtype=np.float32)\n",
    "        ref_s = cv.resize(ref_img, None, fx=pyr_scale, fy=pyr_scale)\n",
    "        cur_s = cv.resize(cur_img, None, fx=pyr_scale, fy=pyr_scale)\n",
    "        Hs = detect_homography(ref_s, cur_s)\n",
    "        if Hs is None: return None\n",
    "        H = np.linalg.inv(S(pyr_scale)) @ Hs @ S(pyr_scale)\n",
    "    else:\n",
    "        H = detect_homography(ref_img, cur_img)\n",
    "        if H is None: return None\n",
    "\n",
    "    out = []\n",
    "    for name, x, y, w, h in ref_rows:\n",
    "        x2, y2, w2, h2 = project_rect(x, y, w, h, H)\n",
    "        out.append((name, x2, y2, w2, h2))\n",
    "    return out\n",
    "\n",
    "# ---------- Entrance-based bout detection ----------\n",
    "def _grab(frame, r):\n",
    "    return frame[r[\"ystart\"]:r[\"ystart\"]+r[\"ylen\"], r[\"xstart\"]:r[\"xstart\"]+r[\"xlen\"]]\n",
    "\n",
    "def compute_roi_baselines(cap, rois: Dict[str,Dict[str,int]], num_frames=10, thresh_value=160):\n",
    "    thresholds = {k: 0.0 for k in rois}; n = 0\n",
    "    pos = int(cap.get(cv.CAP_PROP_POS_FRAMES))\n",
    "    for _ in range(num_frames):\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) if frame.ndim == 3 else frame\n",
    "        _, bw = cv.threshold(gray, thresh_value, 255, cv.THRESH_BINARY)\n",
    "        for name, rect in rois.items():\n",
    "            thresholds[name] += float(np.sum(_grab(bw, rect)))\n",
    "        n += 1\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, pos)\n",
    "    if n == 0:\n",
    "        raise RuntimeError(\"Could not read frames to compute baselines.\")\n",
    "    for k in thresholds: thresholds[k] /= n\n",
    "    return thresholds\n",
    "\n",
    "def detect_bouts_by_entrances(\n",
    "    video_path: str,\n",
    "    rois_csv: str,\n",
    "    thresh_value: int = 160,\n",
    "    threshold_factor: float = 0.5,\n",
    "    min_duration_s: float = 0.4,\n",
    "    merge_gap_s: float = 0.2,\n",
    "):\n",
    "    df = pd.read_csv(rois_csv)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    rois = {str(n).lower(): {\"xstart\":int(x), \"ystart\":int(y), \"xlen\":int(w), \"ylen\":int(h)}\n",
    "            for n,x,y,w,h in df[[\"name\",\"x\",\"y\",\"w\",\"h\"]].itertuples(index=False, name=None)}\n",
    "    if \"entrance1\" not in rois or \"entrance2\" not in rois:\n",
    "        raise ValueError(\"ROIs must include 'entrance1' and 'entrance2'.\")\n",
    "\n",
    "    cap = open_video_any(str(video_path))\n",
    "    if cap is None:\n",
    "        raise FileNotFoundError(f\"Cannot open video: {video_path}\")\n",
    "    fps = cap.get(cv.CAP_PROP_FPS) or 0.0\n",
    "    if fps <= 1e-3: fps = 30.0\n",
    "    total_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT)) or None\n",
    "\n",
    "    baselines = compute_roi_baselines(cap, rois, num_frames=10, thresh_value=thresh_value)\n",
    "    def occupied(bw, name):\n",
    "        return (np.sum(_grab(bw, rois[name])) < baselines[name] * threshold_factor)\n",
    "\n",
    "    ent1_prev = False; ent2_prev = False\n",
    "    hasLeft1 = False; hasLeft2 = False\n",
    "    entered = False\n",
    "    bouts = []\n",
    "    cur_start = None\n",
    "\n",
    "    frame_idx = 0\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) if frame.ndim == 3 else frame\n",
    "        _, bw = cv.threshold(gray, thresh_value, 255, cv.THRESH_BINARY)\n",
    "\n",
    "        e1_now = occupied(bw, \"entrance1\")\n",
    "        e2_now = occupied(bw, \"entrance2\")\n",
    "\n",
    "        left1 = (not e1_now) and ent1_prev\n",
    "        left2 = (not e2_now) and ent2_prev\n",
    "\n",
    "        if left1:\n",
    "            hasLeft1 = True\n",
    "            if hasLeft2 and entered:\n",
    "                # EXIT (sequence 2->1)\n",
    "                end_s = frame_idx / fps\n",
    "                if cur_start is not None:\n",
    "                    bouts.append((cur_start, end_s))\n",
    "                cur_start = None\n",
    "                entered = False\n",
    "                hasLeft1 = hasLeft2 = False\n",
    "\n",
    "        if left2:\n",
    "            hasLeft2 = True\n",
    "            if hasLeft1 and not entered:\n",
    "                # ENTER (sequence 1->2)\n",
    "                cur_start = frame_idx / fps\n",
    "                entered = True\n",
    "\n",
    "        ent1_prev, ent2_prev = e1_now, e2_now\n",
    "        frame_idx += 1\n",
    "\n",
    "    if entered and cur_start is not None:\n",
    "        end_s = (total_frames / fps) if total_frames else (frame_idx / fps)\n",
    "        bouts.append((cur_start, end_s))\n",
    "    cap.release()\n",
    "\n",
    "    # merge gaps and drop shorts\n",
    "    if not bouts:\n",
    "        return []\n",
    "    merged = []\n",
    "    s0, e0 = bouts[0]\n",
    "    for s, e in bouts[1:]:\n",
    "        if s - e0 <= merge_gap_s:\n",
    "            e0 = e\n",
    "        else:\n",
    "            merged.append((s0, e0))\n",
    "            s0, e0 = s, e\n",
    "    merged.append((s0, e0))\n",
    "    return [(s, e) for (s, e) in merged if (e - s) >= min_duration_s]\n",
    "\n",
    "# ---------- Cut segments ----------\n",
    "def cut_segment_ffmpeg(video, start_s, end_s, out_path, reencode=True):\n",
    "    ensure_ffmpeg()\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if reencode:\n",
    "        cmd = [\n",
    "            ffmpeg_bin(), \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "            \"-ss\", f\"{start_s:.3f}\", \"-t\", f\"{max(0.0, end_s - start_s):.3f}\",\n",
    "            \"-i\", str(video),\n",
    "            \"-map\", \"0:v:0?\", \"-c:v\", \"libx264\", \"-preset\", \"veryfast\", \"-crf\", \"18\",\n",
    "            \"-movflags\", \"+faststart\", \"-reset_timestamps\", \"1\", str(out_path)\n",
    "        ]\n",
    "    else:\n",
    "        cmd = [\n",
    "            ffmpeg_bin(), \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "            \"-ss\", f\"{start_s:.3f}\", \"-to\", f\"{end_s:.3f}\",\n",
    "            \"-i\", str(video),\n",
    "            \"-map\", \"0:v:0?\", \"-c\", \"copy\",\n",
    "            \"-movflags\", \"+faststart\", \"-reset_timestamps\", \"1\", str(out_path)\n",
    "        ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "def segment_video_by_detected_bouts(\n",
    "    video_path: str,\n",
    "    rois_csv: str,\n",
    "    outdir: str,\n",
    "    base_label: str,\n",
    "    padding_s: float,\n",
    "    reencode: bool,\n",
    "    thresh_value: int,\n",
    "    threshold_factor: float,\n",
    "    min_duration_s: float,\n",
    "    merge_gap_s: float,\n",
    "):\n",
    "    bouts = detect_bouts_by_entrances(\n",
    "        video_path, rois_csv,\n",
    "        thresh_value=thresh_value,\n",
    "        threshold_factor=threshold_factor,\n",
    "        min_duration_s=min_duration_s,\n",
    "        merge_gap_s=merge_gap_s,\n",
    "    )\n",
    "    segments = []\n",
    "    for i, (s, e) in enumerate(bouts):\n",
    "        s2 = max(0.0, s - padding_s)\n",
    "        e2 = max(s2, e + padding_s)\n",
    "        out_name = f\"{base_label}_trial_{i:03d}.mp4\"\n",
    "        out_path = Path(outdir) / out_name\n",
    "        cut_segment_ffmpeg(video_path, s2, e2, out_path, reencode=reencode)\n",
    "        segments.append({\"trial_index\": i, \"start_s\": s, \"end_s\": e, \"path\": str(out_path)})\n",
    "    return segments\n",
    "\n",
    "def update_trials_csv_with_paths(trials_csv: str, segments, column_name=\"video_segment_path\", inplace=False):\n",
    "    trials_csv = Path(trials_csv).resolve()\n",
    "    df = pd.read_csv(trials_csv)\n",
    "    paths = [seg[\"path\"] for seg in segments]\n",
    "    n = min(len(df), len(paths))\n",
    "    if column_name not in df.columns:\n",
    "        df[column_name] = pd.NA\n",
    "    df.loc[:n-1, column_name] = paths[:n]\n",
    "    updated = trials_csv if inplace else trials_csv.with_name(trials_csv.stem + \"_with_segments_detected.csv\")\n",
    "    df.to_csv(updated, index=False)\n",
    "    return str(updated), n, len(paths), len(df)\n",
    "\n",
    "def build_outdir(video_path: Path):\n",
    "    return video_path.parent / \"segments_detected\" / video_path.stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ee029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw once on your REFERENCE_VIDEO; saves to REF_ROIS_CSV\n",
    "ref_rows = draw_rois_on_first_frame(REFERENCE_VIDEO, roi_names=ROI_NAMES, scale=2.0)\n",
    "save_rois_csv(Path(REF_ROIS_CSV), ref_rows)\n",
    "print(\"Saved reference ROIs ->\", REF_ROIS_CSV)\n",
    "\n",
    "# Quick visual check (press any key to close window)\n",
    "first = grab_first_frame(REFERENCE_VIDEO)\n",
    "vis = overlay_rois(first, ref_rows)\n",
    "cv.imshow(\"Reference ROIs\", vis); cv.waitKey(0); cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste or run your code that builds the {trial_csv: video} dict here.\n",
    "# Example:\n",
    "# csv_video = {\"C:/.../mouse6359_session3.6_trial_info.csv\": \"C:/.../6359_2024-08-28_13_28_27s3.6.mp4\", ...}\n",
    "\n",
    "print(\"Pairs:\", len(csv_video))\n",
    "# Optional: sanity check the first few\n",
    "for k, v in list(csv_video.items())[:3]:\n",
    "    print(\"CSV:\", k)\n",
    "    print(\"VID:\", v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = []\n",
    "\n",
    "# Load reference once\n",
    "ref_frame = grab_first_frame(REFERENCE_VIDEO)\n",
    "ref_rows  = load_rois_long(REF_ROIS_CSV)\n",
    "\n",
    "for trials_csv, video in csv_video.items():\n",
    "    video_p = Path(video).resolve()\n",
    "    trials_p = Path(trials_csv).resolve()\n",
    "\n",
    "    if not video_p.exists():\n",
    "        print(f\"[SKIP] Video not found: {video_p}\")\n",
    "        continue\n",
    "    if not trials_p.exists():\n",
    "        print(f\"[SKIP] CSV not found: {trials_p}\")\n",
    "        continue\n",
    "\n",
    "    # Prepare per-session ROI CSV path\n",
    "    session_rois_csv = video_p.with_suffix(\"\").as_posix() + \"_rois.csv\"\n",
    "\n",
    "    # If missing, adapt from reference via homography\n",
    "    if not Path(session_rois_csv).exists():\n",
    "        cur_frame = grab_first_frame(str(video_p))\n",
    "        if cur_frame is None:\n",
    "            print(f\"[SKIP] Cannot open video for ROI adaptation: {video_p.name}\")\n",
    "            continue\n",
    "        adapted = auto_rois_from_reference(cur_frame, ref_frame, ref_rows, pyr_scale=PYR_SCALE)\n",
    "        if adapted is None:\n",
    "            if FALLBACK_TO_REF_ROIS:\n",
    "                print(f\"[WARN] Homography failed for {video_p.name} -> using reference ROIs\")\n",
    "                rows = ref_rows\n",
    "            else:\n",
    "                print(f\"[SKIP] Homography failed and fallback disabled: {video_p.name}\")\n",
    "                continue\n",
    "        else:\n",
    "            rows = adapted\n",
    "        save_rois_csv(Path(session_rois_csv), rows)\n",
    "\n",
    "        # Optional: save a preview image of the adapted ROIs\n",
    "        try:\n",
    "            preview = overlay_rois(cur_frame, rows)\n",
    "            outdir = build_outdir(video_p)\n",
    "            outdir.mkdir(parents=True, exist_ok=True)\n",
    "            cv.imwrite(str(outdir / \"rois_preview.png\"), preview)\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] Could not save ROI preview:\", e)\n",
    "\n",
    "    # Segment by detected bouts\n",
    "    outdir = build_outdir(video_p)\n",
    "    segs = segment_video_by_detected_bouts(\n",
    "        video_path=str(video_p),\n",
    "        rois_csv=session_rois_csv,\n",
    "        outdir=str(outdir),\n",
    "        base_label=video_p.stem,\n",
    "        padding_s=PADDING_S,\n",
    "        reencode=REENCODE,\n",
    "        thresh_value=THRESH_VALUE,\n",
    "        threshold_factor=THRESH_FACTOR,\n",
    "        min_duration_s=MIN_DURATION_S,\n",
    "        merge_gap_s=MERGE_GAP_S,\n",
    "    )\n",
    "\n",
    "    # Update the CSV with paths (row order -> segment order)\n",
    "    updated_csv_path, filled, n_segments, n_rows = update_trials_csv_with_paths(\n",
    "        trials_csv=str(trials_p),\n",
    "        segments=segs,\n",
    "        column_name=COLUMN_NAME,\n",
    "        inplace=False,  # write *_with_segments_detected.csv\n",
    "    )\n",
    "\n",
    "    summaries.append({\n",
    "        \"video\": str(video_p),\n",
    "        \"roi_csv\": session_rois_csv,\n",
    "        \"segments_outdir\": str(outdir),\n",
    "        \"segments_made\": len(segs),\n",
    "        \"csv_original\": str(trials_p),\n",
    "        \"csv_updated\": updated_csv_path,\n",
    "        \"rows_filled\": filled,\n",
    "        \"csv_rows\": n_rows\n",
    "    })\n",
    "\n",
    "print(\"Done. Sessions processed:\", len(summaries))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f802622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(summaries)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
