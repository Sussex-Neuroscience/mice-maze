{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "select_pts=0 #1 to select--> you have to run the other selection scripts first\n",
    "if select_pts==1:\n",
    "    reward_pts= pickle.load(sys.stdin)\n",
    "else:\n",
    "     reward_pts = [[(250, 125), (290, 200)],[(330, 125), (370, 200)],[(250, 315), (290, 390)], [(330, 315), (370, 390)]]\n",
    "\n",
    "\n",
    "# function to collect the differences between frames to later decide if there was any movement in the reward areas.\n",
    "def diffImg(t0, t1, t2):\n",
    "    d1 = cv2.absdiff(t2, t1)\n",
    "    d2 = cv2.absdiff(t1, t0)\n",
    "    return cv2.bitwise_and(d1, d2)\n",
    "\n",
    "\n",
    "# Same command function as streaming, its just now we pass in the file path, nice!\n",
    "cap = cv2.VideoCapture('C:/Users/isabe/Downloads/mice_movie.mp4') # add a 0 to connect to the camera \n",
    "time.sleep(2)# give it time to load\n",
    "\n",
    "# FRAMES PER SECOND FOR VIDEO\n",
    "fps = 60\n",
    "\n",
    "# Always a good idea to check if the video was acutally there\n",
    "# If you get an error at thsi step, triple check your file path!!\n",
    "if cap.isOpened()== False: \n",
    "    print(\"Error opening the video file. Please double check your file path for typos. Or move the movie file to the same location as this script/notebook\")\n",
    "    \n",
    "        \n",
    "##\n",
    "mice_loc=np.zeros(len(reward_pts))\n",
    "# Create a kernel\n",
    "kernel=np.ones((5,5), np.uint8)\n",
    "#cv2.namedWindow('Test')\n",
    "\n",
    "first_frame=None \n",
    "ret, frame = cap.read()\n",
    "    \n",
    "  #While the video is opened\n",
    "while cap.isOpened():\n",
    "    \n",
    "        \n",
    "    # Read the video file.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If we got frames, show them.\n",
    "    if ret == True:\n",
    "         \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)#convert to gray scale\n",
    "        gray = cv2.GaussianBlur(gray, (21,21),0)# blur image for better object detection\n",
    "        if first_frame is None:\n",
    "            first_frame=gray\n",
    "            continue\n",
    "        \n",
    "        delta_frame = cv2.absdiff(first_frame,gray) # get only the stuck that is not static \n",
    "        thresh_frame = cv2.threshold(delta_frame, 80, 255, cv2.THRESH_BINARY)[1] #binary threshold\n",
    "        thresh_frame = cv2.morphologyEx(thresh_frame, cv2.MORPH_GRADIENT, kernel)\n",
    "         \n",
    "            \n",
    "            #find the mouse \n",
    "        (cnts,hierarchy) = cv2.findContours(thresh_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        \n",
    "        #draw around the mouse \n",
    "        for contour in cnts:\n",
    "            #if cv2.contourArea(contour) < 4000:\n",
    "             #   continue\n",
    "\n",
    "            (x,y, w, h)= cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h),(0,225,0),2)\n",
    "            \n",
    "        #find out in mouse is in the rward area \n",
    "        for i in range (0, len(cnts)):\n",
    "            (x,y, w, h)= cv2.boundingRect(cnts[i])\n",
    "            xCentre=int(x+0.5*w)\n",
    "            yCentre=int(y+0.5*h)\n",
    "            cv2.circle(img=frame,center=(xCentre,yCentre),radius=5,color=(255,0,0),thickness=2)  \n",
    "            result=np.zeros(len(reward_pts))    \n",
    "            for r in range(0, len(reward_pts)): #len(reward_pts)\n",
    "                #rewardArea= cv2.rectangle(thresh_frame,pt1=reward_pts[i][0],pt2=reward_pts[i][1],color=(255,0,0),thickness=2)\n",
    "                rewardContour=np.array([[1,1],reward_pts[r][0],reward_pts[r][1]],  dtype=np.int32)\n",
    "\n",
    "            \n",
    "            #### Check if the point was in the reward area: \n",
    "                result[r] = cv2.pointPolygonTest(rewardContour, (xCentre,yCentre), False)\n",
    "          \n",
    "        \n",
    "        # save in the array the result of whether the mouse is in or out\n",
    "        mice_loc=np.vstack([mice_loc,result])# a\n",
    "        #cv2.imshow(\"Delta Frame\",delta_frame)\n",
    "       # cv2.imshow(\"Capturing\",gray)\n",
    "        cv2.imshow(\"Threshold Frame\",thresh_frame) # to see the object detection\n",
    "        cv2.imshow(\"Color Frame\",frame) # actual video \n",
    "\n",
    "        key = cv2.waitKey(5)\n",
    "        \n",
    "        \n",
    "         # Display the frame at same frame rate of recording\n",
    "        time.sleep(1/fps)# only needed for video- not camera\n",
    "        \n",
    "        \n",
    "     \n",
    "       # cv2.imshow('Test',frame)\n",
    " \n",
    "        # Press q to quit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            \n",
    "            break\n",
    "            \n",
    "      \n",
    "    # Or automatically break this whole loop if the video is over.\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "mice_loc.tofile('test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "cap.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(526, 4)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mice_loc.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
